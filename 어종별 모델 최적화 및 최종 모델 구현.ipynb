{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62f9d31",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2744991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ba5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "import statsmodels.api as sm\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e62ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y, y_pred):\n",
    "    return mean_squared_error(y, y_pred)**0.5\n",
    "\n",
    "\n",
    "def train_model(train_data, target_data, model=LinearRegression()):  # baseline model : LInearRegression\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_data, target_data, random_state=0)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    print(\"Model Training Complete!\")\n",
    "\n",
    "    pred_train, pred_test = model.predict(x_train), model.predict(x_test)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "#     plt.scatter(pred_train, y_train, s=10)\n",
    "    sns.regplot(pred_train, y_train, color='g')\n",
    "    plt.xlabel(\"Predicted price\")\n",
    "    plt.ylabel(\"Actual price\")\n",
    "    plt.show()\n",
    "\n",
    "    # cvs = cross_val_score(model, x_test, y_test, cv = 5)\n",
    "    # print(\">> cross_val_score mean =\", cvs.mean())\n",
    "    print(\">> RMSE train =\", RMSE(y_train, pred_train))\n",
    "    print(\">> RMSE validation =\", RMSE(y_test, pred_test))\n",
    "    print(\">> MAE train =\", mean_absolute_error(pred_train, y_train))\n",
    "    print(\">> MAE validation =\", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "def print_importance(model, df, added_columns):\n",
    "    importance = model.coef_\n",
    "    fs_data = []\n",
    "    for i, x in enumerate(importance):\n",
    "        fs_data.append([abs(x), df.columns[i]])\n",
    "    fs_data.sort(key=lambda x: x[0], reverse=True)\n",
    "   \n",
    "    # 추가한 컬럼의 중요도\n",
    "    for i in range(len(fs_data)):\n",
    "        if fs_data[i][1] in added_columns:\n",
    "            print(fs_data[i][1], \":\", fs_data[i][0] ,\">\", i, \"순위\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"총\", len(fs_data) , \"개\")\n",
    "    \n",
    "    return fs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e88788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04641709",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(), 'DATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f889e78",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a152e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(root, 'preprocessed_train_notencoded.csv'))\n",
    "df_weather_code = pd.read_csv(os.path.join(root, 'raw_weather_code.csv'), header=0, index_col=0)\n",
    "weather_list = [pd.read_csv(os.path.join(root, 'raw_weather_20151228_20161227.csv'), encoding='cp949') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20161228_20171227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20171228_20181227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20181228_20191227.csv'), encoding='cp949') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20191228_20201227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20201228_20210818.csv'), encoding='euc-kr')]\n",
    "df_exchange = pd.read_csv(os.path.join(root, 'preprocessed_exchange.csv'))\n",
    "df_oil = pd.read_csv(os.path.join(root, 'preprocessed_oil.csv'))\n",
    "df_weather_kr = pd.read_csv(os.path.join(root, 'preprocessed_weather_korea.csv'))\n",
    "df_cpi = pd.read_csv(os.path.join(root, 'preprocessed_cpi.csv'))\n",
    "df_weather_with_wf = pd.read_csv(os.path.join(root, 'df_weather_with_wf.csv')) # 3-2 전처리 가설 검증 df_weather_with_wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f55b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_squid = pd.read_csv(os.path.join(root, 'final_squid.csv'))\n",
    "final_salmon = pd.read_csv(os.path.join(root, 'final_salmon.csv'))\n",
    "final_whiteleg_shrimp = pd.read_csv(os.path.join(root, 'final_whiteleg_shrimp.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393b5a4",
   "metadata": {},
   "source": [
    "# Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5842e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scaler(data, col, scaler = None):\n",
    "  \n",
    "  '''\n",
    "  정규화 함수\n",
    "  data : dataframe\n",
    "  column : P_PRICE\n",
    "  scaler : standard, robust, minmax, log\n",
    "\n",
    "  '''\n",
    " \n",
    "  features = data.drop(col, axis=1)\n",
    "  target = data[col]\n",
    "\n",
    "  if scaler == 'standard':\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "  elif scaler == 'robust':\n",
    "    scaler = RobustScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "  elif scaler == 'minmax':\n",
    "    scaler = MinMaxScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "  elif scaler == 'log':\n",
    "    features = np.log1p(features)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "  elif scaler == 'None':\n",
    "\n",
    "    return features, target\n",
    "\n",
    "\n",
    "################################################################################################################################################\n",
    "\n",
    "def model_train(data, col, scaler, model = None):\n",
    "\n",
    "  '''\n",
    "  \n",
    "  data : dataframe\n",
    "  column : P_PRICE\n",
    "  scaler : standard, robust, minmax, log\n",
    "  model_name : linear, ridge, lasso, elastic, decisiontree,\n",
    "               randomforest, ada, gradient, xgb, lgbm\n",
    "\n",
    "  '''\n",
    "\n",
    "  features, target = model_scaler(data, col, scaler)\n",
    "  x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "  \n",
    "  if model == 'linear': \n",
    "    \n",
    "    model = LinearRegression()\n",
    "    neg_mse_scores = cross_val_score(model, features, target, scoring = 'neg_mean_squared_error', cv = 10)\n",
    "    rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "\n",
    "    print('RMSE : {:.4f}'.format(avg_rmse))\n",
    "\n",
    "  elif model == 'ridge':\n",
    "    \n",
    "    params = {\n",
    "              'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "              'fit_intercept':(True, False),\n",
    "              'normalize':(True, False),\n",
    "\n",
    "              }\n",
    "\n",
    "    ridge = Ridge(random_state=0)\n",
    "    final = RandomizedSearchCV(ridge, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(x_train, y_train)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "    \n",
    "  elif model == 'lasso':\n",
    "\n",
    "    params = {\n",
    "              'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "              'fit_intercept':(True, False),\n",
    "              'normalize':(True, False),\n",
    "\n",
    "              }\n",
    "\n",
    "    lasso = Lasso(random_state=0)\n",
    "    final = RandomizedSearchCV(lasso, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "  \n",
    "  elif model == 'elastic':\n",
    "    \n",
    "\n",
    "    params = {\n",
    "       'alpha': (0.1, 0.01, 0.5, 1, 3, 5, 10),\n",
    "       'l1_ratio':(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.1, 0.1)\n",
    "    }\n",
    "\n",
    "    elastic = ElasticNet()\n",
    "    final = RandomizedSearchCV(elastic, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "  elif model == 'decisiontree':\n",
    "    \n",
    "    params = {\n",
    "              'max_depth': [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],            \n",
    "               #'min_child_samples': randint(5, 50),\n",
    "              'min_samples_split':[1,3,5,7,10,15,20,25,30,45,50,60,70,80,90,100],\n",
    "              'min_samples_leaf': [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              \n",
    "    }\n",
    "\n",
    "    dt = DecisionTreeRegressor(random_state=0)\n",
    "    final = RandomizedSearchCV(dt, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "  elif model == 'randomforest':\n",
    "    \n",
    "    params = {\n",
    "              'max_depth': [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],           \n",
    "              'n_estimators':[1,5,10,30,50,70,100,200,500,750,1000],\n",
    "               #'min_child_samples': randint(5, 50),\n",
    "              'min_samples_leaf':[1,3,5,7,10,20,30,50,70,100],\n",
    "              'min_samples_split': [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              'max_leaf_nodes': [1,3,5,7,10,20,30,50,70,100,200,500,700,800,900,1000],\n",
    "\n",
    "              }\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=0)\n",
    "    final = RandomizedSearchCV(rf, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "\n",
    "\n",
    "  elif model == 'gradinet':\n",
    "\n",
    "    params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'subsample' : (0.01, 0.1, 0.5, 0.08, 0.35, 0.3, 0.001, 0.03, 0.006, 0.153, 0.193, 0.0012, 0.0083 ,1),\n",
    "              'min_samples_split' : [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              }   \n",
    "\n",
    "    grad = GradientBoostingRegressor()\n",
    "    final = RandomizedSearchCV(grad, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "\n",
    "  elif model == 'xgb':\n",
    "    \n",
    "    params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }   \n",
    "\n",
    "    xgb = XGBRegressor()\n",
    "    final = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "\n",
    "  elif model == 'lgbm':\n",
    "    params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "              }   \n",
    "\n",
    "    lgbm = LGBMRegressor()\n",
    "    final = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b8762aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "params = {\n",
    "              'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "              'fit_intercept':(True, False),\n",
    "              'normalize':(True, False),\n",
    "\n",
    "              }\n",
    "\n",
    "ridge = Ridge(random_state=0)\n",
    "ridge = RandomizedSearchCV(ridge, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "   \n",
    "    \n",
    "params = {\n",
    "              'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "              'fit_intercept':(True, False),\n",
    "              'normalize':(True, False),\n",
    "\n",
    "            }\n",
    "\n",
    "lasso = Lasso(random_state=0)\n",
    "lasso = RandomizedSearchCV(lasso, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "   \n",
    "  \n",
    " \n",
    "params = {\n",
    "       'alpha': (0.1, 0.01, 0.5, 1, 3, 5, 10),\n",
    "       'l1_ratio':(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.1, 0.1)\n",
    "    }\n",
    "\n",
    "elastic = ElasticNet()\n",
    "elastic = RandomizedSearchCV(elastic, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "    \n",
    "params = {\n",
    "              'max_depth': [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],            \n",
    "               #'min_child_samples': randint(5, 50),\n",
    "              'min_samples_split':[1,3,5,7,10,15,20,25,30,45,50,60,70,80,90,100],\n",
    "              'min_samples_leaf': [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              \n",
    "}\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "dt = RandomizedSearchCV(dt, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    \n",
    "\n",
    "params = {\n",
    "              'max_depth': [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],           \n",
    "              'n_estimators':[1,5,10,30,50,70,100,200,500,750,1000],\n",
    "               #'min_child_samples': randint(5, 50),\n",
    "              'min_samples_leaf':[1,3,5,7,10,20,30,50,70,100],\n",
    "              'min_samples_split': [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              'max_leaf_nodes': [1,3,5,7,10,20,30,50,70,100,200,500,700,800,900,1000],\n",
    "\n",
    "              }\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf = RandomizedSearchCV(rf, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "   \n",
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'subsample' : (0.01, 0.1, 0.5, 0.08, 0.35, 0.3, 0.001, 0.03, 0.006, 0.153, 0.193, 0.0012, 0.0083 ,1),\n",
    "              'min_samples_split' : [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              }   \n",
    "\n",
    "grad = GradientBoostingRegressor()\n",
    "grad = RandomizedSearchCV(grad, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    " \n",
    "\n",
    "    \n",
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }   \n",
    "\n",
    "xgb = XGBRegressor()\n",
    "xgb = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "   \n",
    "    \n",
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "              }   \n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819af15",
   "metadata": {},
   "source": [
    "## Squid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9971d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.1501\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4800009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'normalize': True, 'fit_intercept': True, 'alpha': 0.096}\n",
      "Best Score: 0.12206861725166937\n",
      "Predict RMSE: 0.1626957782896132\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49813784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'normalize': True, 'fit_intercept': True, 'alpha': 0.0001}\n",
      "Best Score: 0.15702166279295537\n",
      "Predict RMSE: 0.1595538236708253\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b863e7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'l1_ratio': 0.0001, 'alpha': 0.01}\n",
      "Best Score: 0.20122630732618185\n",
      "Predict RMSE: 0.18051767645464795\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','elastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdfbbf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 70, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 50, 'max_depth': 900}\n",
      "Best Score: 0.18353165233240087\n",
      "Predict RMSE: 0.07106474916144664\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc3fd4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'subsample': 1, 'n_estimators': 500, 'min_samples_split': 100, 'max_depth': 15, 'learning_rate': 0.1}\n",
      "Best Score: 0.1719998772322185\n",
      "Predict RMSE: 0.0016386649539780857\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','gradinet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "164f8c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 30, 'min_child_weight': 9, 'max_depth': 1200, 'learning_rate': 0.185}\n",
      "Best Score: 0.16119482808859867\n",
      "Predict RMSE: 0.059627489206877916\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46fd5097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'num_leaves': 9, 'n_estimators': 500, 'min_child_weight': 1, 'min_child_samples': 7, 'max_depth': 9, 'learning_rate': 0.351}\n",
      "Best Score: 0.16562126524280638\n",
      "Predict RMSE: 3.4465778408468502e-06\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31796d4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict RMSE: 0.15250106684348835\n"
     ]
    }
   ],
   "source": [
    "single_models = [ \n",
    "    ( 'linear_reg' , lr), \n",
    "    ( 'ridge' , ridge), \n",
    "    ( 'lasso' , lasso), \n",
    "    ( 'elasticnet' , elastic), \n",
    "    ( 'decisiontree' , dt), \n",
    "    ( 'randomforest' , rf),\n",
    "    ( 'gradient' , grad),\n",
    "    ( 'xgb' , xgb),\n",
    "    ( 'lgbm' , lgbm),\n",
    "]\n",
    "\n",
    "\n",
    "squid_voting = VotingRegressor(single_models, n_jobs= -1)\n",
    "\n",
    "features = final_squid.drop('P_PRICE', axis=1)\n",
    "target = final_squid['P_PRICE']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "\n",
    "squid_voting.fit(x_train,y_train)\n",
    "\n",
    "pred = squid_voting.predict(x_test) \n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0c9da4",
   "metadata": {},
   "source": [
    "Score와 RMSE가 모두 좋은 xgb 모델을 최종 모델로 선택\n",
    "\n",
    "\n",
    "Voting 모델과 비교 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0657c570",
   "metadata": {},
   "source": [
    "## Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd1d3ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.0996\n"
     ]
    }
   ],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aeab5a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'normalize': True, 'fit_intercept': False, 'alpha': 0.003}\n",
      "Best Score: 0.07729361267527128\n",
      "Predict RMSE: 0.09405174930179246\n"
     ]
    }
   ],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8ed367ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'normalize': True, 'fit_intercept': True, 'alpha': 0.01}\n",
      "Best Score: 0.08829866482950782\n",
      "Predict RMSE: 0.09756407193707708\n"
     ]
    }
   ],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b216631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 70, 'min_samples_split': 15, 'min_samples_leaf': 70, 'max_leaf_nodes': 200, 'max_depth': 50}\n",
      "Best Score: 0.08829604112969916\n",
      "Predict RMSE: 0.09741355196009162\n"
     ]
    }
   ],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f0d0c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'subsample': 0.3, 'n_estimators': 1, 'min_samples_split': 5, 'max_depth': 50, 'learning_rate': 0.096}\n",
      "Best Score: 0.08567583794274984\n",
      "Predict RMSE: 0.09134239397277158\n"
     ]
    }
   ],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','gradinet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d271fa2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 70, 'min_child_weight': 5, 'max_depth': 700, 'learning_rate': 0.185}\n",
      "Best Score: 0.08308510631019256\n",
      "Predict RMSE: 0.006221793636250067\n"
     ]
    }
   ],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "59adfad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'num_leaves': 9, 'n_estimators': 500, 'min_child_weight': 1, 'min_child_samples': 7, 'max_depth': 9, 'learning_rate': 0.351}\n",
      "Best Score: 0.08679137478138159\n",
      "Predict RMSE: 9.383943228628539e-07\n"
     ]
    }
   ],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12b5c1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict RMSE: 0.07313749904524906\n"
     ]
    }
   ],
   "source": [
    "single_models = [ \n",
    "    ( 'linear_reg' , lr), \n",
    "    ( 'ridge' , ridge), \n",
    "    ( 'lasso' , lasso), \n",
    "    ( 'elasticnet' , elastic), \n",
    "    ( 'decisiontree' , dt), \n",
    "    ( 'randomforest' , rf),\n",
    "    ( 'gradient' , grad),\n",
    "    ( 'xgb' , xgb),\n",
    "    ( 'lgbm' , lgbm),\n",
    "]\n",
    "\n",
    "\n",
    "salmon_voting = VotingRegressor(single_models, n_jobs= -1)\n",
    "\n",
    "features = final_salmon.drop('P_PRICE', axis=1)\n",
    "target = final_salmon['P_PRICE']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "\n",
    "salmon_voting.fit(x_train,y_train)\n",
    "\n",
    "pred = salmon_voting.predict(x_test) \n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79e14c",
   "metadata": {},
   "source": [
    "Score와 RMSE가 모두 좋은 xgb 모델을 최종 모델로 선택\n",
    "\n",
    "Voting 모델과 비교 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c821e0",
   "metadata": {},
   "source": [
    "## Whiteleg_shrimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d725cb48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.0686\n"
     ]
    }
   ],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0f68e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'normalize': True, 'fit_intercept': True, 'alpha': 0.096}\n",
      "Best Score: 0.0643035790861109\n",
      "Predict RMSE: 0.06155358109928038\n"
     ]
    }
   ],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67039fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'normalize': True, 'fit_intercept': True, 'alpha': 0.0001}\n",
      "Best Score: 0.06903210678435484\n",
      "Predict RMSE: 0.05910512469864875\n"
     ]
    }
   ],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b2f89649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 30, 'min_samples_split': 20, 'min_samples_leaf': 3, 'max_leaf_nodes': 1000, 'max_depth': 475}\n",
      "Best Score: 0.06453594728752406\n",
      "Predict RMSE: 0.03720533118564567\n"
     ]
    }
   ],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c33d4b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'subsample': 0.35, 'n_estimators': 10, 'min_samples_split': 55, 'max_depth': 250, 'learning_rate': 0.351}\n",
      "Best Score: 0.06681935370706339\n",
      "Predict RMSE: 0.04700956830936692\n"
     ]
    }
   ],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','gradinet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ba8cd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 30, 'min_child_weight': 9, 'max_depth': 1200, 'learning_rate': 0.185}\n",
      "Best Score: 0.07026569307523202\n",
      "Predict RMSE: 0.024090612869304123\n"
     ]
    }
   ],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "088fe30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'num_leaves': 3, 'n_estimators': 100, 'min_child_weight': 0.5, 'min_child_samples': 9, 'max_depth': 50, 'learning_rate': 0.01825}\n",
      "Best Score: 0.06718620875185184\n",
      "Predict RMSE: 0.04997575729838162\n"
     ]
    }
   ],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "be968f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict RMSE: 0.05586801200340817\n"
     ]
    }
   ],
   "source": [
    "single_models = [ \n",
    "    ( 'linear_reg' , lr), \n",
    "    ( 'ridge' , ridge), \n",
    "    ( 'lasso' , lasso), \n",
    "    ( 'elasticnet' , elastic), \n",
    "    ( 'decisiontree' , dt), \n",
    "    ( 'randomforest' , rf),\n",
    "    ( 'gradient' , grad),\n",
    "    ( 'xgb' , xgb),\n",
    "    ( 'lgbm' , lgbm),\n",
    "]\n",
    "\n",
    "\n",
    "whiteleg_shrimp_voting = VotingRegressor(single_models, n_jobs= -1)\n",
    "\n",
    "features = final_whiteleg_shrimp.drop('P_PRICE', axis=1)\n",
    "target = final_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "\n",
    "whiteleg_shrimp_voting.fit(x_train,y_train)\n",
    "\n",
    "pred = whiteleg_shrimp_voting.predict(x_test) \n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc3845",
   "metadata": {},
   "source": [
    "Score와 RMSE가 모두 좋은 lgbm 모델을 최종 모델로 선택\n",
    "\n",
    "Voting 모델과 비교 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c9425f",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282d143",
   "metadata": {},
   "source": [
    "### Squid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "756aebe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#        'alpha': (0.1, 0.01, 0.5, 1, 3, 5, 10),\n",
    "#        'l1_ratio':(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.1, 0.1)\n",
    "#     }\n",
    "\n",
    "# elastic = ElasticNet()\n",
    "# squid_final = RandomizedSearchCV(elastic, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "\n",
    "# features = final_squid.drop('P_PRICE',axis=1)\n",
    "# target = final_squid['P_PRICE']\n",
    "\n",
    "# squid_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10fefcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#               'max_depth':  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],           \n",
    "#               'n_estimators':[1,5,10,30,50,70,100,200,500,750,1000],\n",
    "#                #'min_child_samples': randint(5, 50),\n",
    "#               'min_samples_leaf':[1,3,5,7,10,20,30,50,70,100],\n",
    "#               'min_samples_split': [1,3,5,7,10,20,30,50,70,100],\n",
    "#               'max_leaf_nodes': [1,3,5,7,10,20,30,50,70,100,200,500,700,800,900,1000],\n",
    "\n",
    "#               }\n",
    "\n",
    "# rf = RandomForestRegressor(random_state=0)\n",
    "# squid_final = RandomizedSearchCV(rf, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_squid.drop('P_PRICE',axis=1)\n",
    "# target = final_squid['P_PRICE']\n",
    "\n",
    "# squid_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5451944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100,...\n",
       "                   param_distributions={'learning_rate': (0.01, 0.0001, 0.003,\n",
       "                                                          0.5, 0.04, 0.008,\n",
       "                                                          0.001, 0.351, 0.096,\n",
       "                                                          0.853, 0.185, 0.01825,\n",
       "                                                          0.012385, 0.1),\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 15, 25, 50,\n",
       "                                                      100, 200, 300, 400, 450,\n",
       "                                                      500, 550, 700, 800, 900,\n",
       "                                                      1000],\n",
       "                                        'min_child_weight': [0, 0.05, 0.5, 1, 3,\n",
       "                                                             5, 7, 9, 15, 25,\n",
       "                                                             50, 100, 200, 300,\n",
       "                                                             500, 700],\n",
       "                                        'n_estimators': [1, 5, 10, 30, 50, 70,\n",
       "                                                         100, 200, 500, 1000]},\n",
       "                   random_state=0, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }\n",
    "\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "squid_final = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "features = final_squid.drop('P_PRICE',axis=1)\n",
    "target = final_squid['P_PRICE']\n",
    "\n",
    "squid_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd8497bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "#               'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "#               'max_depth' : [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "#               'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "#               }   \n",
    "\n",
    "# lgbm = LGBMRegressor()\n",
    "# squid_final = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_squid.drop('P_PRICE',axis=1)\n",
    "# target = final_squid['P_PRICE']\n",
    "\n",
    "\n",
    "# squid_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02c049",
   "metadata": {},
   "source": [
    "### Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0b58e005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#               'max_depth':  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],           \n",
    "#               'n_estimators':[1,5,10,30,50,70,100,200,500,750,1000],\n",
    "#                #'min_child_samples': randint(5, 50),\n",
    "#               'min_samples_leaf':[1,3,5,7,10,20,30,50,70,100],\n",
    "#               'min_samples_split': [1,3,5,7,10,20,30,50,70,100],\n",
    "#               'max_leaf_nodes': [1,3,5,7,10,20,30,50,70,100,200,500,700,800,900,1000],\n",
    "\n",
    "#               }\n",
    "\n",
    "# rf = RandomForestRegressor(random_state=0)\n",
    "# salmon_final = RandomizedSearchCV(rf, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_salmon.drop('P_PRICE',axis=1)\n",
    "# target = final_salmon['P_PRICE']\n",
    "\n",
    "# salmon_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f910f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10,\n",
       "                   estimator=XGBRegressor(base_score=None, booster=None,\n",
       "                                          colsample_bylevel=None,\n",
       "                                          colsample_bynode=None,\n",
       "                                          colsample_bytree=None, gamma=None,\n",
       "                                          gpu_id=None, importance_type='gain',\n",
       "                                          interaction_constraints=None,\n",
       "                                          learning_rate=None,\n",
       "                                          max_delta_step=None, max_depth=None,\n",
       "                                          min_child_weight=None, missing=nan,\n",
       "                                          monotone_constraints=None,\n",
       "                                          n_estimators=100,...\n",
       "                   param_distributions={'learning_rate': (0.01, 0.0001, 0.003,\n",
       "                                                          0.5, 0.04, 0.008,\n",
       "                                                          0.001, 0.351, 0.096,\n",
       "                                                          0.853, 0.185, 0.01825,\n",
       "                                                          0.012385, 0.1),\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 15, 25, 50,\n",
       "                                                      100, 200, 300, 400, 450,\n",
       "                                                      500, 550, 700, 800, 900,\n",
       "                                                      1000],\n",
       "                                        'min_child_weight': [0, 0.05, 0.5, 1, 3,\n",
       "                                                             5, 7, 9, 15, 25,\n",
       "                                                             50, 100, 200, 300,\n",
       "                                                             500, 700],\n",
       "                                        'n_estimators': [1, 5, 10, 30, 50, 70,\n",
       "                                                         100, 200, 500, 1000]},\n",
       "                   random_state=0, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }   \n",
    "\n",
    "xgb = XGBRegressor()\n",
    "salmon_final = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "features = final_salmon.drop('P_PRICE',axis=1)\n",
    "target = final_salmon['P_PRICE']\n",
    "\n",
    "salmon_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e1b19f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "#               'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "#               'max_depth' : [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "#               'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "#               }   \n",
    "\n",
    "# lgbm = LGBMRegressor()\n",
    "# salmon_final = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_salmon.drop('P_PRICE',axis=1)\n",
    "# target = final_salmon['P_PRICE']\n",
    "\n",
    "\n",
    "# salmon_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ed30da",
   "metadata": {},
   "source": [
    "### Whiteleg Shrimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e39084ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#               'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "#               'fit_intercept':(True, False),\n",
    "#               'normalize':(True, False),\n",
    "\n",
    "#               }\n",
    "\n",
    "# lasso = Lasso(random_state=0)\n",
    "# whiteleg_shrimp_final = RandomizedSearchCV(lasso, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_whiteleg_shrimp.drop('P_PRICE',axis=1)\n",
    "# target = final_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "# whiteleg_shrimp_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b32d07df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {\n",
    "#               'max_depth':  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],           \n",
    "#               'n_estimators':[1,5,10,30,50,70,100,200,500,750,1000],\n",
    "#                #'min_child_samples': randint(5, 50),\n",
    "#               'min_samples_leaf':[1,3,5,7,10,20,30,50,70,100],\n",
    "#               'min_samples_split': [1,3,5,7,10,20,30,50,70,100],\n",
    "#               'max_leaf_nodes': [1,3,5,7,10,20,30,50,70,100,200,500,700,800,900,1000],\n",
    "\n",
    "#               }\n",
    "\n",
    "# rf = RandomForestRegressor(random_state=0)\n",
    "# whiteleg_shrimp_final = RandomizedSearchCV(rf, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_whiteleg_shrimp.drop('P_PRICE',axis=1)\n",
    "# target = final_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "# whiteleg_shrimp_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75ea52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "#               'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "#               'max_depth' :  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "#               'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               }   \n",
    "\n",
    "# xgb = XGBRegressor()\n",
    "# whiteleg_shrimp_final = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_whiteleg_shrimp.drop('P_PRICE',axis=1)\n",
    "# target = final_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "# whiteleg_shrimp_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d7ad2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=LGBMRegressor(), n_iter=50, n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': (0.01, 0.0001, 0.003,\n",
       "                                                          0.5, 0.04, 0.008,\n",
       "                                                          0.001, 0.351, 0.096,\n",
       "                                                          0.853, 0.185, 0.01825,\n",
       "                                                          0.012385, 0.1),\n",
       "                                        'max_depth': [1, 3, 5, 7, 9, 15, 25, 50,\n",
       "                                                      100, 200, 300, 400, 450,\n",
       "                                                      500, 550, 700, 800, 900,\n",
       "                                                      1000],\n",
       "                                        'min_child_samples': [1, 3, 5, 7, 9, 15,\n",
       "                                                              25, 50, 100, 200,\n",
       "                                                              300, 500, 700],\n",
       "                                        'min_child_weight': [0, 0.05, 0.5, 1, 3,\n",
       "                                                             5, 7, 9, 15, 25,\n",
       "                                                             50, 100, 200, 300,\n",
       "                                                             500, 700],\n",
       "                                        'n_estimators': [1, 5, 10, 30, 50, 70,\n",
       "                                                         100, 200, 500, 1000],\n",
       "                                        'num_leaves': [1, 3, 5, 7, 9, 15, 25,\n",
       "                                                       50, 100, 200, 300, 500,\n",
       "                                                       700]},\n",
       "                   random_state=0, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "              'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "              }   \n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "whiteleg_shrimp_final = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "features = final_whiteleg_shrimp.drop('P_PRICE',axis=1)\n",
    "target = final_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "whiteleg_shrimp_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881445c",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8481c04",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc25df",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5f04488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(os.path.join(root, 'test.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d69be",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "485f6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data용 \n",
    "def check_week(df):\n",
    "    \"\"\"\n",
    "    dataframe에 sdate 과 edate 사이에 모든 데이터가 있는지 확인하는 함수\n",
    "    :param df: 검사하고자 하는 dataframe (set_week 형태)\n",
    "    :return: 데이터가 전체 존재하는지 여부\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    sdate = date(2020, 1, 6)  # start date\n",
    "    edate = date(2020, 12, 28)  # end date\n",
    "    delta = edate - sdate  # as timedelta\n",
    "    mem = set()\n",
    "\n",
    "    for i in range(delta.days + 1):\n",
    "        day = sdate + timedelta(days=i)\n",
    "        year, week = day.isocalendar()[0], day.isocalendar()[1]\n",
    "        if year * 100 + week in mem:\n",
    "            continue\n",
    "        mem.add(year * 100 + week)\n",
    "        if df[(df['year'] == year) & (df['week'] == week)].empty:\n",
    "            print((year, week), end=\"\")\n",
    "            cnt += 1\n",
    "    if cnt > 0:\n",
    "        print()\n",
    "    print(\"missing\", cnt, \"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90cd589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_week(df_test, 'REG_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "62473246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing 0 values\n"
     ]
    }
   ],
   "source": [
    "check_week(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569cb197",
   "metadata": {},
   "source": [
    "#### Squid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cfa03f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTRY_1</th>\n",
       "      <th>CTRY_2</th>\n",
       "      <th>P_PRICE</th>\n",
       "      <th>year</th>\n",
       "      <th>week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>중국</td>\n",
       "      <td>중국</td>\n",
       "      <td>2.706303</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>중국</td>\n",
       "      <td>중국</td>\n",
       "      <td>1.940000</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>페루</td>\n",
       "      <td>칠레</td>\n",
       "      <td>2.195883</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>페루</td>\n",
       "      <td>칠레</td>\n",
       "      <td>1.922647</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>페루</td>\n",
       "      <td>페루</td>\n",
       "      <td>2.855495</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9421</th>\n",
       "      <td>페루</td>\n",
       "      <td>페루</td>\n",
       "      <td>2.160000</td>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9422</th>\n",
       "      <td>페루</td>\n",
       "      <td>페루</td>\n",
       "      <td>2.910000</td>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9428</th>\n",
       "      <td>페루</td>\n",
       "      <td>페루</td>\n",
       "      <td>1.330000</td>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9433</th>\n",
       "      <td>중국</td>\n",
       "      <td>중국</td>\n",
       "      <td>2.090000</td>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9468</th>\n",
       "      <td>중국</td>\n",
       "      <td>중국</td>\n",
       "      <td>3.150000</td>\n",
       "      <td>2020</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CTRY_1 CTRY_2   P_PRICE  year  week\n",
       "15       중국     중국  2.706303  2020     2\n",
       "16       중국     중국  1.940000  2020     2\n",
       "39       페루     칠레  2.195883  2020     2\n",
       "40       페루     칠레  1.922647  2020     2\n",
       "41       페루     페루  2.855495  2020     2\n",
       "...     ...    ...       ...   ...   ...\n",
       "9421     페루     페루  2.160000  2020    53\n",
       "9422     페루     페루  2.910000  2020    53\n",
       "9428     페루     페루  1.330000  2020    53\n",
       "9433     중국     중국  2.090000  2020    53\n",
       "9468     중국     중국  3.150000  2020    53\n",
       "\n",
       "[509 rows x 5 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_squid = df_test[(df_test['P_NAME']=='오징어') & ((df_test['CTRY_1']=='페루') | (df_test['CTRY_1']=='중국') | (df_test['CTRY_1']=='칠레')) & ((df_test['CTRY_2']=='페루') | (df_test['CTRY_2']=='중국') | (df_test['CTRY_2']=='칠레'))]\n",
    "\n",
    "df_test_squid = df_test_squid[['CTRY_1','CTRY_2','P_PRICE','year','week']]\n",
    "\n",
    "df_test_squid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6fc965",
   "metadata": {},
   "source": [
    "##### Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "84d409e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = df_test_squid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00435a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_weather_with_wf, how='left', on=['year', 'week', 'CTRY_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2f2d92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_weather_kr, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d238147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_oil, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a71e254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_cpi, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5cf307a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_exchange, how='left', on=['year', 'week', 'CTRY_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3feb17",
   "metadata": {},
   "source": [
    "##### Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b2e4240",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTRY_1              0\n",
       "CTRY_2              0\n",
       "P_PRICE             0\n",
       "year                0\n",
       "week                0\n",
       "rain              266\n",
       "wind              266\n",
       "temperature       266\n",
       "wind_kr             0\n",
       "temperature_kr      0\n",
       "water_temp_kr       0\n",
       "oil                 0\n",
       "cpi_total           0\n",
       "cpi_fish            0\n",
       "exchange            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_squid_add.isna().sum() # 페루 날씨 데이터 결측값 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0af12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = df_test_squid_add.sort_values('CTRY_1')\n",
    "\n",
    "df_test_squid_add.fillna(method='ffill',inplace=True)  # 가까운 나라인 칠레 데이터로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fea09ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTRY_1            0\n",
       "CTRY_2            0\n",
       "P_PRICE           0\n",
       "year              0\n",
       "week              0\n",
       "rain              0\n",
       "wind              0\n",
       "temperature       0\n",
       "wind_kr           0\n",
       "temperature_kr    0\n",
       "water_temp_kr     0\n",
       "oil               0\n",
       "cpi_total         0\n",
       "cpi_fish          0\n",
       "exchange          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_squid_add.isna().sum() # 결측값 처리 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c3a23",
   "metadata": {},
   "source": [
    "##### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d2d368b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = df_test_squid_add.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "20afa854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add['temp_kr'] = (df_test_squid_add['temperature_kr'] + df_test_squid_add['water_temp_kr'] + df_test_squid_add['wind_kr']) / 3\n",
    "df_test_squid_add['cpi'] = df_test_squid_add['cpi_fish'] / df_test_squid_add['cpi_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef99d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add.drop(columns=['temperature_kr', 'cpi_fish', 'water_temp_kr','wind_kr' ,'cpi_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f360aa6",
   "metadata": {},
   "source": [
    "##### Final Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "19d44a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_squid = df_test_squid_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66edd1",
   "metadata": {},
   "source": [
    "#### Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "0f6cd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon = df_test[(df_test['P_NAME']=='연어') & (df_test['CTRY_1']=='노르웨이') & (df_test['CTRY_2']=='노르웨이')]\n",
    "\n",
    "df_test_salmon = df_test_salmon[['CTRY_1','CTRY_2','P_PRICE','year','week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6da346",
   "metadata": {},
   "source": [
    "##### Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "106dcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = df_test_salmon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8b66f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_weather_with_wf, how='left', on=['year', 'week', 'CTRY_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f8f58ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_weather_kr, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6f564e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_oil, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28715975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_cpi, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8e5bec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_exchange, how='left', on=['year', 'week','CTRY_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bc60e",
   "metadata": {},
   "source": [
    "##### Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "643c4a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTRY_1              0\n",
       "CTRY_2              0\n",
       "P_PRICE             0\n",
       "year                0\n",
       "week                0\n",
       "rain              232\n",
       "wind              232\n",
       "temperature       232\n",
       "wind_kr             0\n",
       "temperature_kr      0\n",
       "water_temp_kr       0\n",
       "oil                 0\n",
       "cpi_total           0\n",
       "cpi_fish            0\n",
       "exchange            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_salmon_add.isna().sum() # 날씨 데이터 결측값 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0c432eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 값으로 대체\n",
    "\n",
    "df_test_salmon_add['rain'].fillna(np.mean(df_test_salmon_add['rain']),inplace=True)\n",
    "df_test_salmon_add['wind'].fillna(np.mean(df_test_salmon_add['wind']),inplace=True)\n",
    "df_test_salmon_add['temperature'].fillna(np.mean(df_test_salmon_add['temperature']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f454706f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTRY_1            0\n",
       "CTRY_2            0\n",
       "P_PRICE           0\n",
       "year              0\n",
       "week              0\n",
       "rain              0\n",
       "wind              0\n",
       "temperature       0\n",
       "wind_kr           0\n",
       "temperature_kr    0\n",
       "water_temp_kr     0\n",
       "oil               0\n",
       "cpi_total         0\n",
       "cpi_fish          0\n",
       "exchange          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_salmon_add.isna().sum() # 결측값 처리 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c246775",
   "metadata": {},
   "source": [
    "##### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fa0ce680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = df_test_salmon_add.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "93bc452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add['temp_kr'] = (df_test_salmon_add['temperature_kr'] + df_test_salmon_add['water_temp_kr'] + df_test_salmon_add['wind_kr']) / 3\n",
    "df_test_salmon_add['cpi'] = df_test_salmon_add['cpi_fish'] / df_test_salmon_add['cpi_total'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6a8ca3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add.drop(columns=['temperature_kr', 'cpi_fish', 'water_temp_kr','wind_kr', 'cpi_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c768f",
   "metadata": {},
   "source": [
    "##### Final Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39431bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_salmon = df_test_salmon_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd1f08",
   "metadata": {},
   "source": [
    "#### Whiteleg Shrimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "acc3f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp = df_test[(df_test['P_NAME']=='흰다리새우') & ((df_test['CTRY_1']=='베트남') | (df_test['CTRY_1']=='태국')) & ((df_test['CTRY_2']=='베트남') | (df_test['CTRY_2']=='태국'))]\n",
    "\n",
    "df_test_whiteleg_shrimp = df_test_whiteleg_shrimp[['CTRY_1','CTRY_2','P_PRICE','year','week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94737d55",
   "metadata": {},
   "source": [
    "##### Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2b0203a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = df_test_whiteleg_shrimp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fccbfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_weather_with_wf, how='left', on=['year', 'week', 'CTRY_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e48e289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_weather_kr, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "da4cc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_oil, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3cd1d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_cpi, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9f4e8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_exchange, how='left', on=['year', 'week','CTRY_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53141cda",
   "metadata": {},
   "source": [
    "##### Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44e3c934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CTRY_1            0\n",
       "CTRY_2            0\n",
       "P_PRICE           0\n",
       "year              0\n",
       "week              0\n",
       "rain              0\n",
       "wind              0\n",
       "temperature       0\n",
       "wind_kr           0\n",
       "temperature_kr    0\n",
       "water_temp_kr     0\n",
       "oil               0\n",
       "cpi_total         0\n",
       "cpi_fish          0\n",
       "exchange          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_whiteleg_shrimp_add.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589e022",
   "metadata": {},
   "source": [
    "##### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "425db190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = df_test_whiteleg_shrimp_add.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f361dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add['temp_kr'] = (df_test_whiteleg_shrimp_add['temperature_kr'] + df_test_whiteleg_shrimp_add['water_temp_kr'] + df_test_whiteleg_shrimp_add['wind_kr']) / 3\n",
    "df_test_whiteleg_shrimp_add['cpi'] = df_test_whiteleg_shrimp_add['cpi_fish'] / df_test_whiteleg_shrimp_add['cpi_total'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b7b09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add.drop(columns=['temperature_kr', 'cpi_fish', 'water_temp_kr','wind_kr', 'cpi_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ad269",
   "metadata": {},
   "source": [
    "##### Final Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "30ca5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_whiteleg_shrimp = df_test_whiteleg_shrimp_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b316a3",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af32b0d",
   "metadata": {},
   "source": [
    "### Squid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b4453aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 50, 'min_child_weight': 7, 'max_depth': 450, 'learning_rate': 0.1}\n",
      "Best Score: 0.16434064230223452\n",
      "Predict RMSE: 0.3346805322008568\n"
     ]
    }
   ],
   "source": [
    "squid_test_features = final_test_squid.drop('P_PRICE',axis=1)\n",
    "squid_test_target = final_test_squid['P_PRICE']\n",
    "\n",
    "pred = squid_final.predict(squid_test_features)\n",
    "\n",
    "print('Best Params:', squid_final.best_params_)\n",
    "print('Best Score:', np.sqrt(-1 *squid_final.best_score_))\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(squid_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2a9d7fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict RMSE: 17415.281837141072\n"
     ]
    }
   ],
   "source": [
    "pred = squid_voting.predict(squid_test_features)\n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(squid_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea4c1b",
   "metadata": {},
   "source": [
    "RMSE이 더 작은 기존의 best 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbeeda",
   "metadata": {},
   "source": [
    "### Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3f884b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 70, 'min_child_weight': 0.05, 'max_depth': 9, 'learning_rate': 0.185}\n",
      "Best Score: 0.08598306647204754\n",
      "Predict RMSE: 1.1852836932011916\n"
     ]
    }
   ],
   "source": [
    "salmon_test_features = final_test_salmon.drop('P_PRICE',axis=1)\n",
    "salmon_test_target = final_test_salmon['P_PRICE']\n",
    "\n",
    "pred = salmon_final.predict(salmon_test_features)\n",
    "\n",
    "print('Best Params:', salmon_final.best_params_)\n",
    "print('Best Score:', np.sqrt(-1 *salmon_final.best_score_))\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(salmon_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67db1681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict RMSE: 6.539453566568818\n"
     ]
    }
   ],
   "source": [
    "pred = salmon_voting.predict(salmon_test_features)\n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(salmon_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1b6d49",
   "metadata": {},
   "source": [
    "RMSE이 더 작은 기존의 best 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a29f9",
   "metadata": {},
   "source": [
    "### Whiteleg Shrimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f9b6d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'num_leaves': 5, 'n_estimators': 100, 'min_child_weight': 0.05, 'min_child_samples': 9, 'max_depth': 800, 'learning_rate': 0.01}\n",
      "Best Score: 0.0670934975677689\n",
      "Predict RMSE: 1.0338483505365228\n"
     ]
    }
   ],
   "source": [
    "whiteleg_shrimp_test_features = final_test_whiteleg_shrimp.drop('P_PRICE',axis=1)\n",
    "whiteleg_shrimp_test_target = final_test_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "pred = whiteleg_shrimp_final.predict(whiteleg_shrimp_test_features)\n",
    "\n",
    "print('Best Params:', whiteleg_shrimp_final.best_params_)\n",
    "print('Best Score:', np.sqrt(-1 *whiteleg_shrimp_final.best_score_))\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(whiteleg_shrimp_test_target,np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "da5b1459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict RMSE: 130.09925758174577\n"
     ]
    }
   ],
   "source": [
    "pred = whiteleg_shrimp_voting.predict(whiteleg_shrimp_test_features)\n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(whiteleg_shrimp_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca44ca16",
   "metadata": {},
   "source": [
    "RMSE이 더 작은 기존의 best 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78183b32",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "37108acb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test data에 맞게 year,week filtering\n",
    "\n",
    "oil_predict = df_oil[(df_oil['year']==2021) & (df_oil['week']<=26)].groupby(['year','week']).mean()\n",
    "weather_kr_predict = df_weather_kr[(df_weather_kr['year']==2021) & (df_weather_kr['week']<=26)].groupby(['year','week']).mean()\n",
    "cpi_predict = df_cpi[(df_cpi['year']==2021) & (df_cpi['week']<=26)].groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "053c1a03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 파생 변수 추가 및 기존 변수들 제거\n",
    "\n",
    "weather_kr_predict['temp_kr'] = (weather_kr_predict['temperature_kr'] + weather_kr_predict['water_temp_kr'] + weather_kr_predict['wind_kr']) / 3\n",
    "\n",
    "weather_kr_predict.drop(columns=['temperature_kr', 'wind_kr','water_temp_kr'], axis=1, inplace=True)\n",
    "\n",
    "cpi_predict['cpi'] = cpi_predict['cpi_fish'] / cpi_predict['cpi_total'] \n",
    "\n",
    "cpi_predict.drop(columns=['cpi_fish', 'cpi_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322d25f2",
   "metadata": {},
   "source": [
    "## Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2895e5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = oil_predict.copy()\n",
    "\n",
    "df_predict = pd.merge(df_predict,weather_kr_predict,how='left',on=['year','week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3758cd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.merge(df_predict,cpi_predict,how='left',on=['year','week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302dd649",
   "metadata": {},
   "source": [
    "### Squid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaeeac97",
   "metadata": {},
   "source": [
    "오징어 모델용 test features들을 생성. -> 최종 결과값 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8afebaf",
   "metadata": {},
   "source": [
    "#### squid test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d2a36f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오징어 주요 제조국 및 수출국 filtering\n",
    "\n",
    "squid_exchange_predict = df_exchange[(df_exchange['CTRY_2'] == '페루') | (df_exchange['CTRY_2'] == '중국') | (df_exchange['CTRY_2'] == '칠레')]\n",
    "squid_weather_predict = df_weather_with_wf[(df_weather_with_wf['CTRY_1'] == '페루') | (df_weather_with_wf['CTRY_1'] == '중국') | (df_weather_with_wf['CTRY_1'] == '칠레')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5defb49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data에 맞게 year,week filtering\n",
    "\n",
    "squid_exchange_predict = squid_exchange_predict[(squid_exchange_predict['year']==2021) & (squid_exchange_predict['week']<=26)]\n",
    "squid_weather_predict = squid_weather_predict[(squid_weather_predict['year']==2021) & (squid_weather_predict['week']<=26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "72c976d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping\n",
    "\n",
    "squid_exchange_predict = squid_exchange_predict.groupby(['year','week']).mean()\n",
    "squid_weather_predict = squid_weather_predict.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "91263392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Features\n",
    "\n",
    "squid_predict = pd.DataFrame()\n",
    "\n",
    "squid_predict['rain'] = squid_weather_predict['rain']\n",
    "squid_predict['wind'] = squid_weather_predict['wind']\n",
    "squid_predict['temperature'] = squid_weather_predict['temperature']\n",
    "squid_predict['oil'] = df_predict['oil']\n",
    "squid_predict['exchange'] = squid_exchange_predict\n",
    "squid_predict['temp_kr'] = df_predict['temp_kr']\n",
    "squid_predict['cpi'] = df_predict['cpi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4f1b6",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f7db5b25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.532847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.530864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.535233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2.523956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pred\n",
       "0   2.532847\n",
       "1   2.523956\n",
       "2   2.530864\n",
       "3   2.523956\n",
       "4   2.523956\n",
       "5   2.523956\n",
       "6   2.535233\n",
       "7   2.523956\n",
       "8   2.523956\n",
       "9   2.523956\n",
       "10  2.523956\n",
       "11  2.523956\n",
       "12  2.523956\n",
       "13  2.523956\n",
       "14  2.523956\n",
       "15  2.523956\n",
       "16  2.523956\n",
       "17  2.523956\n",
       "18  2.523956\n",
       "19  2.523956\n",
       "20  2.523956\n",
       "21  2.523956\n",
       "22  2.523956\n",
       "23  2.523956\n",
       "24  2.523956\n",
       "25  2.523956"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squid_pred = squid_final.predict(squid_predict)\n",
    "\n",
    "pd.DataFrame({'pred':np.exp(squid_pred)-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6b69d",
   "metadata": {},
   "source": [
    "## Salmon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b38bd",
   "metadata": {},
   "source": [
    "연어 모델용 test features들을 생성. -> 최종 결과값 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "764370cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연어 주요 제조국 및 수출국 filtering\n",
    "\n",
    "salmon_exchange_predict = df_exchange[(df_exchange['CTRY_2'] == '노르웨이')]\n",
    "salmon_weather_predict = df_weather_with_wf[(df_weather_with_wf['CTRY_1'] == '노르웨이')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "17f16fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data에 맞게 year,week filtering\n",
    "\n",
    "salmon_exchange_predict = salmon_exchange_predict[(salmon_exchange_predict['year']==2021) & (salmon_exchange_predict['week']<=26)]\n",
    "salmon_weather_predict = salmon_weather_predict[(salmon_weather_predict['year']==2021) & (salmon_weather_predict['week']<=26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4d49fd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping\n",
    "\n",
    "salmon_exchange_predict = salmon_exchange_predict.groupby(['year','week']).mean()\n",
    "salmon_weather_predict = salmon_weather_predict.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ce57bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Features\n",
    "\n",
    "salmon_predict = pd.DataFrame()\n",
    "\n",
    "salmon_predict['rain'] = salmon_weather_predict['rain']\n",
    "salmon_predict['wind'] = salmon_weather_predict['wind']\n",
    "salmon_predict['temperature'] = salmon_weather_predict['temperature']\n",
    "salmon_predict['oil'] = df_predict['oil']\n",
    "salmon_predict['exchange'] = salmon_exchange_predict\n",
    "salmon_predict['temp_kr'] = df_predict['temp_kr']\n",
    "salmon_predict['cpi'] = df_predict['cpi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa21f0a7",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "4d30df7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.756540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.294503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.627148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>14.055256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.296228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.056583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.267999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.267999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>14.267999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14.267999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.267999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>14.056583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>14.056583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>14.267999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>14.267999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>14.056583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>14.056583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred\n",
       "0   14.756540\n",
       "1   14.296228\n",
       "2   14.296228\n",
       "3   14.296228\n",
       "4   14.294503\n",
       "5   14.627148\n",
       "6   14.296228\n",
       "7   14.296228\n",
       "8   14.296228\n",
       "9   14.296228\n",
       "10  14.296228\n",
       "11  14.296228\n",
       "12  14.055256\n",
       "13  14.296228\n",
       "14  14.056583\n",
       "15  14.267999\n",
       "16  14.267999\n",
       "17  14.267999\n",
       "18  14.267999\n",
       "19  14.267999\n",
       "20  14.056583\n",
       "21  14.056583\n",
       "22  14.267999\n",
       "23  14.267999\n",
       "24  14.056583\n",
       "25  14.056583"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salmon_pred = salmon_final.predict(salmon_predict)\n",
    "\n",
    "pd.DataFrame({'pred':np.exp(salmon_pred)-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1254495",
   "metadata": {},
   "source": [
    "## whiteleg_shrimp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f151b5",
   "metadata": {},
   "source": [
    "흰다리새우 모델용 test features들을 생성. -> 최종 결과값 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "32b81866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흰다리새우 주요 제조국 및 수출국 filtering\n",
    "\n",
    "whiteleg_shrimp_exchange_predict = df_exchange[(df_exchange['CTRY_2'] == '태국') | (df_exchange['CTRY_2'] == '베트남')]\n",
    "whiteleg_shrimp_weather_predict = df_weather_with_wf[(df_weather_with_wf['CTRY_1'] == '태국') | (df_weather_with_wf['CTRY_1'] == '베트남')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b360693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data에 맞게 year,week filtering\n",
    "\n",
    "whiteleg_shrimp_exchange_predict = whiteleg_shrimp_exchange_predict[(whiteleg_shrimp_exchange_predict['year']==2021) & (whiteleg_shrimp_exchange_predict['week']<=26)]\n",
    "whiteleg_shrimp_weather_predict = whiteleg_shrimp_weather_predict[(whiteleg_shrimp_weather_predict['year']==2021) & (whiteleg_shrimp_weather_predict['week']<=26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "944f6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping\n",
    "\n",
    "whiteleg_shrimp_exchange_predict = whiteleg_shrimp_exchange_predict.groupby(['year','week']).mean()\n",
    "whiteleg_shrimp_weather_predict = whiteleg_shrimp_weather_predict.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a8add15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Features\n",
    "\n",
    "whiteleg_shrimp_predict = pd.DataFrame()\n",
    "\n",
    "whiteleg_shrimp_predict['rain'] = whiteleg_shrimp_weather_predict['rain']\n",
    "whiteleg_shrimp_predict['wind'] = whiteleg_shrimp_weather_predict['wind']\n",
    "whiteleg_shrimp_predict['temperature'] = whiteleg_shrimp_weather_predict['temperature']\n",
    "whiteleg_shrimp_predict['oil'] = df_predict['oil']\n",
    "whiteleg_shrimp_predict['exchange'] = whiteleg_shrimp_exchange_predict\n",
    "whiteleg_shrimp_predict['temp_kr'] = df_predict['temp_kr']\n",
    "whiteleg_shrimp_predict['cpi'] = df_predict['cpi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a3013d",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "dfd4b2ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.327505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11.327505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>11.327505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11.327505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>11.327505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.327505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>11.467065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred\n",
       "0   11.467065\n",
       "1   11.467065\n",
       "2   11.327505\n",
       "3   11.467065\n",
       "4   11.467065\n",
       "5   11.467065\n",
       "6   11.327505\n",
       "7   11.327505\n",
       "8   11.327505\n",
       "9   11.327505\n",
       "10  11.327505\n",
       "11  11.467065\n",
       "12  11.467065\n",
       "13  11.467065\n",
       "14  11.467065\n",
       "15  11.467065\n",
       "16  11.467065\n",
       "17  11.467065\n",
       "18  11.467065\n",
       "19  11.467065\n",
       "20  11.467065\n",
       "21  11.467065\n",
       "22  11.467065\n",
       "23  11.467065\n",
       "24  11.467065\n",
       "25  11.467065"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whiteleg_shrimp_pred = whiteleg_shrimp_final.predict(whiteleg_shrimp_predict)\n",
    "\n",
    "pd.DataFrame({'pred': np.exp(whiteleg_shrimp_pred)-1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
