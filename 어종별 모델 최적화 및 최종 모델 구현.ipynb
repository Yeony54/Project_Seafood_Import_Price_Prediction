{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d62f9d31",
   "metadata": {},
   "source": [
    "# Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2744991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ba5290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e62ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSE(y, y_pred):\n",
    "    return mean_squared_error(y, y_pred)**0.5\n",
    "\n",
    "\n",
    "def train_model(train_data, target_data, model=LinearRegression()):  # baseline model : LInearRegression\n",
    "    x_train, x_test, y_train, y_test = train_test_split(train_data, target_data, random_state=0)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    print(\"Model Training Complete!\")\n",
    "\n",
    "    pred_train, pred_test = model.predict(x_train), model.predict(x_test)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "#     plt.scatter(pred_train, y_train, s=10)\n",
    "    sns.regplot(pred_train, y_train, color='g')\n",
    "    plt.xlabel(\"Predicted price\")\n",
    "    plt.ylabel(\"Actual price\")\n",
    "    plt.show()\n",
    "\n",
    "    # cvs = cross_val_score(model, x_test, y_test, cv = 5)\n",
    "    # print(\">> cross_val_score mean =\", cvs.mean())\n",
    "    print(\">> RMSE train =\", RMSE(y_train, pred_train))\n",
    "    print(\">> RMSE validation =\", RMSE(y_test, pred_test))\n",
    "    print(\">> MAE train =\", mean_absolute_error(pred_train, y_train))\n",
    "    print(\">> MAE validation =\", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"-------------------------------------------------\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "    \n",
    "def print_importance(model, df, added_columns):\n",
    "    importance = model.coef_\n",
    "    fs_data = []\n",
    "    for i, x in enumerate(importance):\n",
    "        fs_data.append([abs(x), df.columns[i]])\n",
    "    fs_data.sort(key=lambda x: x[0], reverse=True)\n",
    "   \n",
    "    # 추가한 컬럼의 중요도\n",
    "    for i in range(len(fs_data)):\n",
    "        if fs_data[i][1] in added_columns:\n",
    "            print(fs_data[i][1], \":\", fs_data[i][0] ,\">\", i, \"순위\")\n",
    "    print(\"-------------------------------------------------\")\n",
    "    print(\"총\", len(fs_data) , \"개\")\n",
    "    \n",
    "    return fs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e88788",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, VotingRegressor, GradientBoostingRegressor, VotingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from scipy.stats import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04641709",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(), 'DATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f889e78",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a152e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(os.path.join(root, 'preprocessed_train_notencoded.csv'))\n",
    "df_weather_code = pd.read_csv(os.path.join(root, 'raw_weather_code.csv'), header=0, index_col=0)\n",
    "weather_list = [pd.read_csv(os.path.join(root, 'raw_weather_20151228_20161227.csv'), encoding='cp949') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20161228_20171227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20171228_20181227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20181228_20191227.csv'), encoding='cp949') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20191228_20201227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'raw_weather_20201228_20210818.csv'), encoding='euc-kr')]\n",
    "df_exchange = pd.read_csv(os.path.join(root, 'preprocessed_exchange.csv'))\n",
    "df_oil = pd.read_csv(os.path.join(root, 'preprocessed_oil.csv'))\n",
    "df_weather_kr = pd.read_csv(os.path.join(root, 'preprocessed_weather_korea.csv'))\n",
    "df_cpi = pd.read_csv(os.path.join(root, 'preprocessed_cpi.csv'))\n",
    "df_weather_with_wf = pd.read_csv(os.path.join(root, 'df_weather_with_wf.csv')) # 3-2 전처리 가설 검증 df_weather_with_wf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f55b627",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_squid = pd.read_csv(os.path.join(root, 'final_squid.csv'))\n",
    "final_salmon = pd.read_csv(os.path.join(root, 'final_salmon.csv'))\n",
    "final_whiteleg_shrimp = pd.read_csv(os.path.join(root, 'final_whiteleg_shrimp.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393b5a4",
   "metadata": {},
   "source": [
    "# Best Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5842e82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_scaler(data, col, scaler = None):\n",
    "  \n",
    "  '''\n",
    "  정규화 함수\n",
    "  data : dataframe\n",
    "  column : P_PRICE\n",
    "  scaler : standard, robust, minmax, log\n",
    "\n",
    "  '''\n",
    " \n",
    "  features = data.drop(col, axis=1)\n",
    "  target = data[col]\n",
    "\n",
    "  if scaler == 'standard':\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "  elif scaler == 'robust':\n",
    "    scaler = RobustScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "  elif scaler == 'minmax':\n",
    "    scaler = MinMaxScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "  elif scaler == 'log':\n",
    "    features = np.log1p(features)\n",
    "\n",
    "    return features, target\n",
    "\n",
    "  elif scaler == 'None':\n",
    "\n",
    "    return features, target\n",
    "\n",
    "\n",
    "################################################################################################################################################\n",
    "\n",
    "def model_train(data, col, scaler, model = None):\n",
    "\n",
    "  '''\n",
    "  \n",
    "  data : dataframe\n",
    "  column : P_PRICE\n",
    "  scaler : standard, robust, minmax, log\n",
    "  model_name : linear, ridge, lasso, elastic, decisiontree,\n",
    "               randomforest, ada, gradient, xgb, lgbm\n",
    "\n",
    "  '''\n",
    "\n",
    "  features, target = model_scaler(data, col, scaler)\n",
    "  x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "  \n",
    "  if model == 'linear': \n",
    "    \n",
    "    model = LinearRegression()\n",
    "    neg_mse_scores = cross_val_score(model, features, target, scoring = 'neg_mean_squared_error', cv = 10)\n",
    "    rmse_scores = np.sqrt(-1 * neg_mse_scores)\n",
    "    avg_rmse = np.mean(rmse_scores)\n",
    "\n",
    "\n",
    "    print('RMSE : {:.4f}'.format(avg_rmse))\n",
    "\n",
    "  elif model == 'ridge':\n",
    "    \n",
    "    params = {\n",
    "              'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "              'fit_intercept':(True, False),\n",
    "              'normalize':(True, False),\n",
    "\n",
    "              }\n",
    "\n",
    "    ridge = Ridge(random_state=0)\n",
    "    final = RandomizedSearchCV(ridge, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(x_train, y_train)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "    \n",
    "  elif model == 'lasso':\n",
    "\n",
    "    params = {\n",
    "              'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "              'fit_intercept':(True, False),\n",
    "              'normalize':(True, False),\n",
    "\n",
    "              }\n",
    "\n",
    "    lasso = Lasso(random_state=0)\n",
    "    final = RandomizedSearchCV(lasso, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "  \n",
    "  elif model == 'elastic':\n",
    "    \n",
    "\n",
    "    params = {\n",
    "       'alpha': (0.1, 0.01, 0.5, 1, 3, 5, 10),\n",
    "       'l1_ratio':(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.1, 0.1)\n",
    "    }\n",
    "\n",
    "    elastic = ElasticNet()\n",
    "    final = RandomizedSearchCV(elastic, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "  elif model == 'decisiontree':\n",
    "    \n",
    "    params = {\n",
    "              'max_depth': [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],            \n",
    "               #'min_child_samples': randint(5, 50),\n",
    "              'min_samples_split':[1,3,5,7,10,15,20,25,30,45,50,60,70,80,90,100],\n",
    "              'min_samples_leaf': [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              \n",
    "    }\n",
    "\n",
    "    dt = DecisionTreeRegressor(random_state=0)\n",
    "    final = RandomizedSearchCV(dt, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "  elif model == 'randomforest':\n",
    "    \n",
    "    params = {\n",
    "              'max_depth': [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],           \n",
    "              'n_estimators':[1,5,10,30,50,70,100,200,500,750,1000],\n",
    "               #'min_child_samples': randint(5, 50),\n",
    "              'min_samples_leaf':[1,3,5,7,10,20,30,50,70,100],\n",
    "              'min_samples_split': [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              'max_leaf_nodes': [1,3,5,7,10,20,30,50,70,100,200,500,700,800,900,1000],\n",
    "\n",
    "              }\n",
    "\n",
    "    rf = RandomForestRegressor(random_state=0)\n",
    "    final = RandomizedSearchCV(rf, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "\n",
    "\n",
    "  elif model == 'gradinet':\n",
    "\n",
    "    params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'subsample' : (0.01, 0.1, 0.5, 0.08, 0.35, 0.3, 0.001, 0.03, 0.006, 0.153, 0.193, 0.0012, 0.0083 ,1),\n",
    "              'min_samples_split' : [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              }   \n",
    "\n",
    "    grad = GradientBoostingRegressor()\n",
    "    final = RandomizedSearchCV(grad, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "\n",
    "  elif model == 'xgb':\n",
    "    \n",
    "    params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }   \n",
    "\n",
    "    xgb = XGBRegressor()\n",
    "    final = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))\n",
    "\n",
    "  elif model == 'lgbm':\n",
    "    params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "              }   \n",
    "\n",
    "    lgbm = LGBMRegressor()\n",
    "    final = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "    final.fit(features, target)\n",
    "\n",
    "    pred = final.predict(x_test)\n",
    "\n",
    "    print('Best Params:', final.best_params_)\n",
    "    print('Best Score:', np.sqrt(-1 *final.best_score_))\n",
    "    print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0ebe885a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "\n",
    "params = {\n",
    "              'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "              'fit_intercept':(True, False),\n",
    "              'normalize':(True, False),\n",
    "\n",
    "              }\n",
    "\n",
    "ridge = Ridge(random_state=0)\n",
    "ridge = RandomizedSearchCV(ridge, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "   \n",
    "    \n",
    "params = {\n",
    "              'alpha': (0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1, 1, 10, 100, 200, 50, 30, 20, 29, 58),            \n",
    "              'fit_intercept':(True, False),\n",
    "              'normalize':(True, False),\n",
    "\n",
    "            }\n",
    "\n",
    "lasso = Lasso(random_state=0)\n",
    "lasso = RandomizedSearchCV(lasso, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "   \n",
    "  \n",
    " \n",
    "params = {\n",
    "       'alpha': (0.1, 0.01, 0.5, 1, 3, 5, 10),\n",
    "       'l1_ratio':(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.1, 0.1)\n",
    "    }\n",
    "\n",
    "elastic = ElasticNet()\n",
    "elastic = RandomizedSearchCV(elastic, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "    \n",
    "params = {\n",
    "              'max_depth': [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],            \n",
    "               #'min_child_samples': randint(5, 50),\n",
    "              'min_samples_split':[1,3,5,7,10,15,20,25,30,45,50,60,70,80,90,100],\n",
    "              'min_samples_leaf': [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              \n",
    "}\n",
    "\n",
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "dt = RandomizedSearchCV(dt, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 1000, n_jobs = -1 ,random_state=0)\n",
    "    \n",
    "\n",
    "params = {\n",
    "              'max_depth': [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],           \n",
    "              'n_estimators':[1,5,10,30,50,70,100,200,500,750,1000],\n",
    "               #'min_child_samples': randint(5, 50),\n",
    "              'min_samples_leaf':[1,3,5,7,10,20,30,50,70,100],\n",
    "              'min_samples_split': [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              'max_leaf_nodes': [1,3,5,7,10,20,30,50,70,100,200,500,700,800,900,1000],\n",
    "\n",
    "              }\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "rf = RandomizedSearchCV(rf, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "   \n",
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'subsample' : (0.01, 0.1, 0.5, 0.08, 0.35, 0.3, 0.001, 0.03, 0.006, 0.153, 0.193, 0.0012, 0.0083 ,1),\n",
    "              'min_samples_split' : [1,3,5,7,10,15,20,25,30,35,40,45,50,55,60,65,70,75,80,85,90,95,100],\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              }   \n",
    "\n",
    "grad = GradientBoostingRegressor()\n",
    "grad = RandomizedSearchCV(grad, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    " \n",
    "\n",
    "    \n",
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }   \n",
    "\n",
    "xgb = XGBRegressor()\n",
    "xgb = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "   \n",
    "    \n",
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' : [1,3,5,7,9,15,25,50,75,100,125,150,175,200,225,250,275,300,325,350,375,400,425,450,475,500,550,600,700,800,900,1000,1100,1200,1500],  \n",
    "              'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "              }   \n",
    "\n",
    "lgbm = LGBMRegressor()\n",
    "lgbm = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8819af15",
   "metadata": {},
   "source": [
    "## Squid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9971d6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE : 0.1504\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4800009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'normalize': True, 'fit_intercept': True, 'alpha': 0.1}\n",
      "Best Score: 0.12461289559596812\n",
      "Predict RMSE: 0.16395828012218305\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49813784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'normalize': True, 'fit_intercept': True, 'alpha': 0.0001}\n",
      "Best Score: 0.1571647029703455\n",
      "Predict RMSE: 0.16141134764055998\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b863e7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'l1_ratio': 0.0001, 'alpha': 0.01}\n",
      "Best Score: 0.19448430765721741\n",
      "Predict RMSE: 0.1802555221723289\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','elastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c68735bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'min_samples_split': 45, 'min_samples_leaf': 7, 'max_depth': 200}\n",
      "Best Score: 0.18554653606317617\n",
      "Predict RMSE: 0.14895550821111503\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','decisiontree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdfbbf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 70, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_leaf_nodes': 50, 'max_depth': 900}\n",
      "Best Score: 0.1811504340147707\n",
      "Predict RMSE: 0.0690766350174073\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc3fd4c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'subsample': 1, 'n_estimators': 500, 'min_samples_split': 100, 'max_depth': 15, 'learning_rate': 0.1}\n",
      "Best Score: 0.17620129798404802\n",
      "Predict RMSE: 0.0015613023963505597\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','gradinet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "164f8c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'n_estimators': 30, 'min_child_weight': 9, 'max_depth': 300, 'learning_rate': 0.351}\n",
      "Best Score: 0.16511883322292426\n",
      "Predict RMSE: 0.029415624763589603\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46fd5097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params: {'num_leaves': 9, 'n_estimators': 500, 'min_child_weight': 1, 'min_child_samples': 7, 'max_depth': 9, 'learning_rate': 0.351}\n",
      "Best Score: 0.1678278178093434\n",
      "Predict RMSE: 1.605712197403056e-06\n"
     ]
    }
   ],
   "source": [
    "model_train(final_squid,'P_PRICE','None','lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ca48e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "single_models = [ \n",
    "    ( 'linear_reg' , lr), \n",
    "    ( 'ridge' , ridge), \n",
    "    ( 'lasso' , lasso), \n",
    "    ( 'elasticnet' , elastic), \n",
    "    ( 'decisiontree' , dt), \n",
    "    ( 'randomforest' , rf),\n",
    "    ( 'gradient' , grad),\n",
    "    ( 'xgb' , xgb),\n",
    "    ( 'lgbm' , lgbm),\n",
    "]\n",
    "\n",
    "\n",
    "squid_voting = VotingRegressor(single_models, n_jobs= -1)\n",
    "\n",
    "features = final_squid.drop('P_PRICE', axis=1)\n",
    "target = final_squid['P_PRICE']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "\n",
    "squid_voting.fit(x_train,y_train)\n",
    "\n",
    "pred = squid_voting.predict(x_test) \n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0c9da4",
   "metadata": {},
   "source": [
    "Score와 RMSE가 모두 좋은 xgb 모델을 최종 모델로 선택\n",
    "\n",
    "\n",
    "Voting 모델과 비교 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0657c570",
   "metadata": {},
   "source": [
    "## Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1d3ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeab5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed367ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b557307",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','elastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3b115c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','decisiontree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b216631",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d0c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','gradinet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d271fa2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59adfad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_salmon,'P_PRICE','None','lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b206a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_models = [ \n",
    "    ( 'linear_reg' , lr), \n",
    "    ( 'ridge' , ridge), \n",
    "    ( 'lasso' , lasso), \n",
    "    ( 'elasticnet' , elastic), \n",
    "    ( 'decisiontree' , dt), \n",
    "    ( 'randomforest' , rf),\n",
    "    ( 'gradient' , grad),\n",
    "    ( 'xgb' , xgb),\n",
    "    ( 'lgbm' , lgbm),\n",
    "]\n",
    "\n",
    "\n",
    "salmon_voting = VotingRegressor(single_models, n_jobs= -1)\n",
    "\n",
    "features = final_salmon.drop('P_PRICE', axis=1)\n",
    "target = final_salmon['P_PRICE']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "\n",
    "salmon_voting.fit(x_train,y_train)\n",
    "\n",
    "pred = salmon_voting.predict(x_test) \n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb79e14c",
   "metadata": {},
   "source": [
    "Score와 RMSE가 모두 좋은 xgb 모델을 최종 모델로 선택\n",
    "\n",
    "Voting 모델과 비교 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c821e0",
   "metadata": {},
   "source": [
    "## Whiteleg_shrimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d725cb48",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f68e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','ridge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67039fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','lasso')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b929f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','elastic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ed001b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','decisiontree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f89649",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','randomforest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d4b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','gradinet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba8cd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','xgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088fe30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train(final_whiteleg_shrimp,'P_PRICE','None','lgbm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f480128",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_models = [ \n",
    "    ( 'linear_reg' , lr), \n",
    "    ( 'ridge' , ridge), \n",
    "    ( 'lasso' , lasso), \n",
    "    ( 'elasticnet' , elastic), \n",
    "    ( 'decisiontree' , dt), \n",
    "    ( 'randomforest' , rf),\n",
    "    ( 'gradient' , grad),\n",
    "    ( 'xgb' , xgb),\n",
    "    ( 'lgbm' , lgbm),\n",
    "]\n",
    "\n",
    "\n",
    "whiteleg_shrimp_voting = VotingRegressor(single_models, n_jobs= -1)\n",
    "\n",
    "features = final_whiteleg_shrimp.drop('P_PRICE', axis=1)\n",
    "target = final_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=0)\n",
    "\n",
    "whiteleg_shrimp_voting.fit(x_train,y_train)\n",
    "\n",
    "pred = whiteleg_shrimp_voting.predict(x_test) \n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(y_test, pred))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fbc3845",
   "metadata": {},
   "source": [
    "Score와 RMSE가 모두 좋은 xgb 모델을 최종 모델로 선택\n",
    "\n",
    "Voting 모델과 비교 예정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c9425f",
   "metadata": {},
   "source": [
    "## Best Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0282d143",
   "metadata": {},
   "source": [
    "### Squid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5451944",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }\n",
    "\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "squid_final = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "features = final_squid.drop('P_PRICE',axis=1)\n",
    "target = final_squid['P_PRICE']\n",
    "\n",
    "squid_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13c8931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "#               'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "#               'max_depth' : [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "#               'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "#               }   \n",
    "\n",
    "# lgbm = LGBMRegressor()\n",
    "# squid_final = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_squid.drop('P_PRICE',axis=1)\n",
    "# target = final_squid['P_PRICE']\n",
    "\n",
    "\n",
    "# squid_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a02c049",
   "metadata": {},
   "source": [
    "### Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f910f31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }   \n",
    "\n",
    "xgb = XGBRegressor()\n",
    "salmon_final = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "features = final_salmon.drop('P_PRICE',axis=1)\n",
    "target = final_salmon['P_PRICE']\n",
    "\n",
    "salmon_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372405de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "#               'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "#               'max_depth' : [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "#               'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "#               }   \n",
    "\n",
    "# lgbm = LGBMRegressor()\n",
    "# salmon_final = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_salmon.drop('P_PRICE',axis=1)\n",
    "# target = final_salmon['P_PRICE']\n",
    "\n",
    "\n",
    "# salmon_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c66ffc2",
   "metadata": {},
   "source": [
    "### Whiteleg Shrimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffaf7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "              'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "              'max_depth' :  [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "              'min_child_weight' :[0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "              }   \n",
    "\n",
    "xgb = XGBRegressor()\n",
    "whiteleg_shrimp_final = RandomizedSearchCV(xgb, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "features = final_whiteleg_shrimp.drop('P_PRICE',axis=1)\n",
    "target = final_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "whiteleg_shrimp_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7ad2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'n_estimators' : [1,5,10,30,50,70,100,200,500,1000],\n",
    "#               'learning_rate' :(0.01, 0.0001, 0.003, 0.5, 0.04, 0.008, 0.001, 0.351, 0.096, 0.853, 0.185, 0.01825, 0.012385, 0.1),\n",
    "#               'max_depth' : [1,3,5,7,9,15,25,50,100,200,300,400,450,500,550,700,800,900,1000],  \n",
    "#               'min_child_weight' : [0,0.05,0.5,1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'num_leaves': [1,3,5,7,9,15,25,50,100,200,300,500,700],\n",
    "#               'min_child_samples':[1,3,5,7,9,15,25,50,100,200,300,500,700],  \n",
    "#               }   \n",
    "\n",
    "# lgbm = LGBMRegressor()\n",
    "# whiteleg_shrimp_final = RandomizedSearchCV(lgbm, param_distributions = params, cv = 10, scoring = 'neg_mean_squared_error', n_iter = 50, n_jobs = -1 ,random_state=0)\n",
    "\n",
    "# features = final_whiteleg_shrimp.drop('P_PRICE',axis=1)\n",
    "# target = final_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "# whiteleg_shrimp_final.fit(features, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5881445c",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8481c04",
   "metadata": {},
   "source": [
    "## Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cc25df",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f04488f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_excel(os.path.join(root, 'test.xlsx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4d69be",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485f6ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data용 \n",
    "def check_week(df):\n",
    "    \"\"\"\n",
    "    dataframe에 sdate 과 edate 사이에 모든 데이터가 있는지 확인하는 함수\n",
    "    :param df: 검사하고자 하는 dataframe (set_week 형태)\n",
    "    :return: 데이터가 전체 존재하는지 여부\n",
    "    \"\"\"\n",
    "    cnt = 0\n",
    "    sdate = date(2020, 1, 6)  # start date\n",
    "    edate = date(2020, 12, 28)  # end date\n",
    "    delta = edate - sdate  # as timedelta\n",
    "    mem = set()\n",
    "\n",
    "    for i in range(delta.days + 1):\n",
    "        day = sdate + timedelta(days=i)\n",
    "        year, week = day.isocalendar()[0], day.isocalendar()[1]\n",
    "        if year * 100 + week in mem:\n",
    "            continue\n",
    "        mem.add(year * 100 + week)\n",
    "        if df[(df['year'] == year) & (df['week'] == week)].empty:\n",
    "            print((year, week), end=\"\")\n",
    "            cnt += 1\n",
    "    if cnt > 0:\n",
    "        print()\n",
    "    print(\"missing\", cnt, \"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90cd589f",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_week(df_test, 'REG_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62473246",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_week(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569cb197",
   "metadata": {},
   "source": [
    "#### Squid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa03f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid = df_test[(df_test['P_NAME']=='오징어') & ((df_test['CTRY_1']=='페루') | (df_test['CTRY_1']=='중국') | (df_test['CTRY_1']=='칠레')) & ((df_test['CTRY_2']=='페루') | (df_test['CTRY_2']=='중국') | (df_test['CTRY_2']=='칠레'))]\n",
    "\n",
    "df_test_squid = df_test_squid[['CTRY_1','CTRY_2','P_PRICE','year','week']]\n",
    "\n",
    "df_test_squid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6fc965",
   "metadata": {},
   "source": [
    "##### Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d409e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = df_test_squid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00435a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_weather_with_wf, how='left', on=['year', 'week', 'CTRY_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2d92dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_weather_kr, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d238147",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_oil, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71e254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_cpi, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf307a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = pd.merge(df_test_squid_add, df_exchange, how='left', on=['year', 'week', 'CTRY_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3feb17",
   "metadata": {},
   "source": [
    "##### Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2e4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add.isna().sum() # 페루 날씨 데이터 결측값 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af12c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = df_test_squid_add.sort_values('CTRY_1')\n",
    "\n",
    "df_test_squid_add.fillna(method='ffill',inplace=True)  # 가까운 나라인 칠레 데이터로 대체"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea09ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add.isna().sum() # 결측값 처리 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07c3a23",
   "metadata": {},
   "source": [
    "##### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d368b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add = df_test_squid_add.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20afa854",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add['temp_kr'] = (df_test_squid_add['temperature_kr'] + df_test_squid_add['water_temp_kr'] + df_test_squid_add['wind_kr']) / 3\n",
    "df_test_squid_add['cpi'] = df_test_squid_add['cpi_fish'] / df_test_squid_add['cpi_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef99d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_squid_add.drop(columns=['temperature_kr', 'cpi_fish', 'water_temp_kr','wind_kr' ,'cpi_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f360aa6",
   "metadata": {},
   "source": [
    "##### Final Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d44a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_squid = df_test_squid_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c66edd1",
   "metadata": {},
   "source": [
    "#### Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6cd7b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon = df_test[(df_test['P_NAME']=='연어') & (df_test['CTRY_1']=='노르웨이') & (df_test['CTRY_2']=='노르웨이')]\n",
    "\n",
    "df_test_salmon = df_test_salmon[['CTRY_1','CTRY_2','P_PRICE','year','week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6da346",
   "metadata": {},
   "source": [
    "##### Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106dcea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = df_test_salmon.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_weather_with_wf, how='left', on=['year', 'week', 'CTRY_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f58ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_weather_kr, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f564e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_oil, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28715975",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_cpi, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = pd.merge(df_test_salmon_add, df_exchange, how='left', on=['year', 'week','CTRY_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4bc60e",
   "metadata": {},
   "source": [
    "##### Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643c4a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add.isna().sum() # 날씨 데이터 결측값 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c432eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 값으로 대체\n",
    "\n",
    "df_test_salmon_add['rain'].fillna(np.mean(df_test_salmon_add['rain']),inplace=True)\n",
    "df_test_salmon_add['wind'].fillna(np.mean(df_test_salmon_add['wind']),inplace=True)\n",
    "df_test_salmon_add['temperature'].fillna(np.mean(df_test_salmon_add['temperature']),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f454706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add.isna().sum() # 결측값 처리 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c246775",
   "metadata": {},
   "source": [
    "##### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0ce680",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add = df_test_salmon_add.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bc452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add['temp_kr'] = (df_test_salmon_add['temperature_kr'] + df_test_salmon_add['water_temp_kr'] + df_test_salmon_add['wind_kr']) / 3\n",
    "df_test_salmon_add['cpi'] = df_test_salmon_add['cpi_fish'] / df_test_salmon_add['cpi_total'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8ca3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_salmon_add.drop(columns=['temperature_kr', 'cpi_fish', 'water_temp_kr','wind_kr', 'cpi_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696c768f",
   "metadata": {},
   "source": [
    "##### Final Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39431bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_salmon = df_test_salmon_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dd1f08",
   "metadata": {},
   "source": [
    "#### Whiteleg Shrimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc3f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp = df_test[(df_test['P_NAME']=='흰다리새우') & ((df_test['CTRY_1']=='베트남') | (df_test['CTRY_1']=='태국')) & ((df_test['CTRY_2']=='베트남') | (df_test['CTRY_2']=='태국'))]\n",
    "\n",
    "df_test_whiteleg_shrimp = df_test_whiteleg_shrimp[['CTRY_1','CTRY_2','P_PRICE','year','week']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94737d55",
   "metadata": {},
   "source": [
    "##### Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0203a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = df_test_whiteleg_shrimp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccbfd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_weather_with_wf, how='left', on=['year', 'week', 'CTRY_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e48e289e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_weather_kr, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_oil, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd1d9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_cpi, how='left', on=['year', 'week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4e8423",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = pd.merge(df_test_whiteleg_shrimp_add, df_exchange, how='left', on=['year', 'week','CTRY_2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53141cda",
   "metadata": {},
   "source": [
    "##### Filling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e3c934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7589e022",
   "metadata": {},
   "source": [
    "##### Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425db190",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add = df_test_whiteleg_shrimp_add.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f361dc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add['temp_kr'] = (df_test_whiteleg_shrimp_add['temperature_kr'] + df_test_whiteleg_shrimp_add['water_temp_kr'] + df_test_whiteleg_shrimp_add['wind_kr']) / 3\n",
    "df_test_whiteleg_shrimp_add['cpi'] = df_test_whiteleg_shrimp_add['cpi_fish'] / df_test_whiteleg_shrimp_add['cpi_total'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7b09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_whiteleg_shrimp_add.drop(columns=['temperature_kr', 'cpi_fish', 'water_temp_kr','wind_kr', 'cpi_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222ad269",
   "metadata": {},
   "source": [
    "##### Final Test DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ca5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_test_whiteleg_shrimp = df_test_whiteleg_shrimp_add"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b316a3",
   "metadata": {},
   "source": [
    "## evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af32b0d",
   "metadata": {},
   "source": [
    "### Squid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4453aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "squid_test_features = final_test_squid.drop('P_PRICE',axis=1)\n",
    "squid_test_target = final_test_squid['P_PRICE']\n",
    "\n",
    "pred = squid_final.predict(squid_test_features)\n",
    "\n",
    "print('Best Params:', squid_final.best_params_)\n",
    "print('Best Score:', np.sqrt(-1 *squid_final.best_score_))\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(squid_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072dd3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = squid_voting.predict(squid_test_features)\n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(squid_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8949a4",
   "metadata": {},
   "source": [
    "RMSE이 더 작은 기존의 best 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbeeda",
   "metadata": {},
   "source": [
    "### Salmon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f884b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "salmon_test_features = final_test_salmon.drop('P_PRICE',axis=1)\n",
    "salmon_test_target = final_test_salmon['P_PRICE']\n",
    "\n",
    "pred = salmon_final.predict(salmon_test_features)\n",
    "\n",
    "print('Best Params:', salmon_final.best_params_)\n",
    "print('Best Score:', np.sqrt(-1 *salmon_final.best_score_))\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(salmon_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876dba8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = salmon_voting.predict(salmon_test_features)\n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(salmon_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa81869",
   "metadata": {},
   "source": [
    "RMSE이 더 작은 기존의 best 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19a29f9",
   "metadata": {},
   "source": [
    "### Whiteleg Shrimp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "whiteleg_shrimp_test_features = final_test_whiteleg_shrimp.drop('P_PRICE',axis=1)\n",
    "whiteleg_shrimp_test_target = final_test_whiteleg_shrimp['P_PRICE']\n",
    "\n",
    "pred = whiteleg_shrimp_final.predict(whiteleg_shrimp_test_features)\n",
    "\n",
    "print('Best Params:', whiteleg_shrimp_final.best_params_)\n",
    "print('Best Score:', np.sqrt(-1 *whiteleg_shrimp_final.best_score_))\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(whiteleg_shrimp_test_target,np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f2c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = whiteleg_shrimp_voting.predict(whiteleg_shrimp_test_features)\n",
    "\n",
    "print('Predict RMSE:',(np.sqrt(mean_squared_error(whiteleg_shrimp_test_target, np.exp(pred)-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefab5f2",
   "metadata": {},
   "source": [
    "RMSE이 더 작은 기존의 best 모델 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b81fbd0",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f26ef07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test data에 맞게 year,week filtering\n",
    "\n",
    "oil_predict = df_oil[(df_oil['year']==2021) & (df_oil['week']<=26)].groupby(['year','week']).mean()\n",
    "weather_kr_predict = df_weather_kr[(df_weather_kr['year']==2021) & (df_weather_kr['week']<=26)].groupby(['year','week']).mean()\n",
    "cpi_predict = df_cpi[(df_cpi['year']==2021) & (df_cpi['week']<=26)].groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e97eb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 파생 변수 추가 및 기존 변수들 제거\n",
    "\n",
    "weather_kr_predict['temp_kr'] = (weather_kr_predict['temperature_kr'] + weather_kr_predict['water_temp_kr'] + weather_kr_predict['wind_kr']) / 3\n",
    "\n",
    "weather_kr_predict.drop(columns=['temperature_kr', 'wind_kr','water_temp_kr'], axis=1, inplace=True)\n",
    "\n",
    "cpi_predict['cpi'] = cpi_predict['cpi_fish'] / cpi_predict['cpi_total'] \n",
    "\n",
    "cpi_predict.drop(columns=['cpi_fish', 'cpi_total'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b3aec",
   "metadata": {},
   "source": [
    "## Merge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9d7d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = oil_predict.copy()\n",
    "\n",
    "df_predict = pd.merge(df_predict,weather_kr_predict,how='left',on=['year','week'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73681c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predict = pd.merge(df_predict,cpi_predict,how='left',on=['year','week'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080632dc",
   "metadata": {},
   "source": [
    "### Squid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110a1c84",
   "metadata": {},
   "source": [
    "오징어 모델용 test features들을 생성. -> 최종 결과값 도출"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537b84a7",
   "metadata": {},
   "source": [
    "#### squid test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdc35f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오징어 주요 제조국 및 수출국 filtering\n",
    "\n",
    "squid_exchange_predict = df_exchange[(df_exchange['CTRY_2'] == '페루') | (df_exchange['CTRY_2'] == '중국') | (df_exchange['CTRY_2'] == '칠레')]\n",
    "squid_weather_predict = df_weather_with_wf[(df_weather_with_wf['CTRY_1'] == '페루') | (df_weather_with_wf['CTRY_1'] == '중국') | (df_weather_with_wf['CTRY_1'] == '칠레')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea89316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data에 맞게 year,week filtering\n",
    "\n",
    "squid_exchange_predict = squid_exchange_predict[(squid_exchange_predict['year']==2021) & (squid_exchange_predict['week']<=26)]\n",
    "squid_weather_predict = squid_weather_predict[(squid_weather_predict['year']==2021) & (squid_weather_predict['week']<=26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd74c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping\n",
    "\n",
    "squid_exchange_predict = squid_exchange_predict.groupby(['year','week']).mean()\n",
    "squid_weather_predict = squid_weather_predict.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdfbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Features\n",
    "\n",
    "squid_predict = pd.DataFrame()\n",
    "\n",
    "squid_predict['rain'] = squid_weather_predict['rain']\n",
    "squid_predict['wind'] = squid_weather_predict['wind']\n",
    "squid_predict['temperature'] = squid_weather_predict['temperature']\n",
    "squid_predict['oil'] = df_predict['oil']\n",
    "squid_predict['exchange'] = squid_exchange_predict\n",
    "squid_predict['temp_kr'] = df_predict['temp_kr']\n",
    "squid_predict['cpi'] = df_predict['cpi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcfd8a",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ceda096",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "squid_pred = squid_final.predict(squid_predict)\n",
    "\n",
    "pd.DataFrame({'pred':np.exp(squid_pred)-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cece9865",
   "metadata": {},
   "source": [
    "## Salmon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037d7a8",
   "metadata": {},
   "source": [
    "연어 모델용 test features들을 생성. -> 최종 결과값 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f59ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연어 주요 제조국 및 수출국 filtering\n",
    "\n",
    "salmon_exchange_predict = df_exchange[(df_exchange['CTRY_2'] == '노르웨이')]\n",
    "salmon_weather_predict = df_weather_with_wf[(df_weather_with_wf['CTRY_1'] == '노르웨이')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c2b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data에 맞게 year,week filtering\n",
    "\n",
    "salmon_exchange_predict = salmon_exchange_predict[(salmon_exchange_predict['year']==2021) & (salmon_exchange_predict['week']<=26)]\n",
    "salmon_weather_predict = salmon_weather_predict[(salmon_weather_predict['year']==2021) & (salmon_weather_predict['week']<=26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cceae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping\n",
    "\n",
    "salmon_exchange_predict = salmon_exchange_predict.groupby(['year','week']).mean()\n",
    "salmon_weather_predict = salmon_weather_predict.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007ba24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Features\n",
    "\n",
    "salmon_predict = pd.DataFrame()\n",
    "\n",
    "salmon_predict['rain'] = salmon_weather_predict['rain']\n",
    "salmon_predict['wind'] = salmon_weather_predict['wind']\n",
    "salmon_predict['temperature'] = salmon_weather_predict['temperature']\n",
    "salmon_predict['oil'] = df_predict['oil']\n",
    "salmon_predict['exchange'] = salmon_exchange_predict\n",
    "salmon_predict['temp_kr'] = df_predict['temp_kr']\n",
    "salmon_predict['cpi'] = df_predict['cpi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a86413",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ad16ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "salmon_pred = salmon_final.predict(salmon_predict)\n",
    "\n",
    "pd.DataFrame({'pred':np.exp(salmon_pred)-1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ede4e2a",
   "metadata": {},
   "source": [
    "## whiteleg_shrimp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb3f2f4",
   "metadata": {},
   "source": [
    "흰다리새우 모델용 test features들을 생성. -> 최종 결과값 도출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c3772d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 흰다리새우 주요 제조국 및 수출국 filtering\n",
    "\n",
    "whiteleg_shrimp_exchange_predict = df_exchange[(df_exchange['CTRY_2'] == '태국') | (df_exchange['CTRY_2'] == '베트남')]\n",
    "whiteleg_shrimp_weather_predict = df_weather_with_wf[(df_weather_with_wf['CTRY_1'] == '태국') | (df_weather_with_wf['CTRY_1'] == '베트남')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b65334d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data에 맞게 year,week filtering\n",
    "\n",
    "whiteleg_shrimp_exchange_predict = whiteleg_shrimp_exchange_predict[(whiteleg_shrimp_exchange_predict['year']==2021) & (whiteleg_shrimp_exchange_predict['week']<=26)]\n",
    "whiteleg_shrimp_weather_predict = whiteleg_shrimp_weather_predict[(whiteleg_shrimp_weather_predict['year']==2021) & (whiteleg_shrimp_weather_predict['week']<=26)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e5f2f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grouping\n",
    "\n",
    "whiteleg_shrimp_exchange_predict = whiteleg_shrimp_exchange_predict.groupby(['year','week']).mean()\n",
    "whiteleg_shrimp_weather_predict = whiteleg_shrimp_weather_predict.groupby(['year','week']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09c01d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Features\n",
    "\n",
    "whiteleg_shrimp_predict = pd.DataFrame()\n",
    "\n",
    "whiteleg_shrimp_predict['rain'] = whiteleg_shrimp_weather_predict['rain']\n",
    "whiteleg_shrimp_predict['wind'] = whiteleg_shrimp_weather_predict['wind']\n",
    "whiteleg_shrimp_predict['temperature'] = whiteleg_shrimp_weather_predict['temperature']\n",
    "whiteleg_shrimp_predict['oil'] = df_predict['oil']\n",
    "whiteleg_shrimp_predict['exchange'] = whiteleg_shrimp_exchange_predict\n",
    "whiteleg_shrimp_predict['temp_kr'] = df_predict['temp_kr']\n",
    "whiteleg_shrimp_predict['cpi'] = df_predict['cpi']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635683b6",
   "metadata": {},
   "source": [
    "#### Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9705e259",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "whiteleg_shrimp_pred = whiteleg_shrimp_final.predict(whiteleg_shrimp_predict)\n",
    "\n",
    "pd.DataFrame({'pred': np.exp(whiteleg_shrimp_pred)-1})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
