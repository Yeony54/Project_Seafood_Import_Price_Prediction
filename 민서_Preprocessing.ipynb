{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Visuzliation Setting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rc\n",
    "from matplotlib import colors\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(), 'DATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel(os.path.join(root, 'train.xlsx'))\n",
    "df_train = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['year'] = df_train['REG_DATE'].dt.year\n",
    "df_train['month'] = df_train['REG_DATE'].dt.month\n",
    "df_train['day'] = df_train['REG_DATE'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_type_list = set()\n",
    "for tmp in df_train.P_IMPORT_TYPE.unique():\n",
    "    for a in tmp.split(','):\n",
    "        import_type_list.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in import_type_list:\n",
    "    df_train[name] = 0\n",
    "    df_train.loc[df_train['P_IMPORT_TYPE'].str.contains(name, regex=False), name] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['VALUE_COUNT'] = 0;\n",
    "value_dict = {}\n",
    "for name, value in zip(df_train['P_NAME'].value_counts().index,df_train['P_NAME'].value_counts()):\n",
    "    value_dict[name] = value\n",
    "\n",
    "def value(col):\n",
    "    return value_dict[col]\n",
    "\n",
    "df_train['VALUE_COUNT'] = df_train['P_NAME'].apply(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_code = pd.read_excel(os.path.join(root, '강수량번호국가매칭.xlsx'), header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "rwt_20152016 = pd.read_csv(os.path.join(root, 'GTS_SYNOP_TIM_20151228-20161227.csv'),encoding='euc-kr') \n",
    "rwt_20162017 = pd.read_csv(os.path.join(root, 'GTS_SYNOP_TIM_20161228-20171227.csv'),encoding='euc-kr') \n",
    "rwt_20172018 = pd.read_csv(os.path.join(root, 'GTS_SYNOP_TIM_20171228-20181227.csv'),encoding='euc-kr') \n",
    "rwt_20182019 = pd.read_csv(os.path.join(root, 'GTS_SYNOP_TIM_20181228-20191227.csv'),encoding='euc-kr') \n",
    "rwt_20192020 = pd.read_csv(os.path.join(root, 'GTS_SYNOP_TIM_20191228-20201227.csv'),encoding='euc-kr') \n",
    "rwt_20202021 = pd.read_csv(os.path.join(root, 'GTS_SYNOP_TIM_20201228-20210818.csv'),encoding='euc-kr')\n",
    "rwt_list = [rwt_20152016, rwt_20162017, rwt_20172018, rwt_20182019, rwt_20192020, rwt_20202021]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지점에 따라 나라명 추가\n",
    "def set_country(row):\n",
    "    data = df_weather_code[df_weather_code[1] == row['지점']]\n",
    "    if data.empty:\n",
    "        return \"\"\n",
    "    return data.iloc[0][2]\n",
    "\n",
    "\n",
    "def preprocess_weather(df_weather):\n",
    "    # 날짜 정보 정리\n",
    "    df_weather['year'] = df_weather['일시'].astype('str').str[:4].astype('int')\n",
    "    df_weather['month'] = df_weather['일시'].astype('str').str[5:7].astype('int')\n",
    "    df_weather['day'] = df_weather['일시'].astype('str').str[8:10].astype('int')\n",
    "    # 1차 평균\n",
    "    df_weather['rain'] = df_weather[['지점', 'year', 'month', 'day', '강수량']].groupby(['지점', 'year', 'month', 'day']).transform('mean')\n",
    "    df_weather['wind'] = df_weather[['지점', 'year', 'month', 'day', '풍속']].groupby(['지점', 'year', 'month', 'day']).transform('mean')\n",
    "    df_weather['temperature'] = df_weather[['지점', 'year', 'month', 'day', '기온']].groupby(['지점', 'year', 'month', 'day']).transform('mean')\n",
    "    # 컬럼/행 정리\n",
    "    df_weather.drop(columns = ['지점명', '일시', '강수량', '풍속', '기온'], inplace=True)\n",
    "    df_weather.drop_duplicates(inplace=True)\n",
    "    # 나라명 추가\n",
    "    df_weather['country'] = \"\"\n",
    "    for i, row in df_weather.iterrows():\n",
    "        df_weather.at[i, 'country'] = set_country(row)\n",
    "    # 2차 평균\n",
    "    df_weather['rain'] = df_weather[['country', 'year', 'month', 'day', 'rain']].groupby(['country', 'year', 'month', 'day']).transform('mean')\n",
    "    df_weather['wind'] = df_weather[['country', 'year', 'month', 'day', 'wind']].groupby(['country', 'year', 'month', 'day']).transform('mean')\n",
    "    df_weather['temperature'] = df_weather[['country', 'year', 'month', 'day', 'temperature']].groupby(['country', 'year', 'month', 'day']).transform('mean')\n",
    "    # 컬럼/행 정리\n",
    "    df_weather.drop(columns = ['지점'], inplace=True)\n",
    "    df_weather.drop_duplicates(inplace=True)\n",
    "    # 인덱스 정리\n",
    "    df_weather.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for df in rwt_list:\n",
    "    preprocess_weather(df)\n",
    "rwt = pd.concat(rwt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13947.000000</td>\n",
       "      <td>13947.000000</td>\n",
       "      <td>13947.000000</td>\n",
       "      <td>9561.000000</td>\n",
       "      <td>11895.000000</td>\n",
       "      <td>11895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018.258407</td>\n",
       "      <td>6.276762</td>\n",
       "      <td>15.697426</td>\n",
       "      <td>-20.158210</td>\n",
       "      <td>3.535292</td>\n",
       "      <td>17.914166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.613987</td>\n",
       "      <td>3.414373</td>\n",
       "      <td>8.809565</td>\n",
       "      <td>79.127632</td>\n",
       "      <td>5.846954</td>\n",
       "      <td>9.676148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-156.116667</td>\n",
       "      <td>-10.577841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-6.661111</td>\n",
       "      <td>2.168701</td>\n",
       "      <td>11.250038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.165833</td>\n",
       "      <td>2.958333</td>\n",
       "      <td>20.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.915909</td>\n",
       "      <td>5.768750</td>\n",
       "      <td>25.950781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>33.145833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year         month           day         rain          wind  \\\n",
       "count  13947.000000  13947.000000  13947.000000  9561.000000  11895.000000   \n",
       "mean    2018.258407      6.276762     15.697426   -20.158210      3.535292   \n",
       "std        1.613987      3.414373      8.809565    79.127632      5.846954   \n",
       "min     2015.000000      1.000000      1.000000  -999.000000   -156.116667   \n",
       "25%     2017.000000      3.000000      8.000000    -6.661111      2.168701   \n",
       "50%     2018.000000      6.000000     16.000000     1.165833      2.958333   \n",
       "75%     2020.000000      9.000000     23.000000     3.915909      5.768750   \n",
       "max     2021.000000     12.000000     31.000000   915.000000     15.125000   \n",
       "\n",
       "        temperature  \n",
       "count  11895.000000  \n",
       "mean      17.914166  \n",
       "std        9.676148  \n",
       "min      -10.577841  \n",
       "25%       11.250038  \n",
       "50%       20.135000  \n",
       "75%       25.950781  \n",
       "max       33.145833  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rwt.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 확인필요\n",
    "- outlier 찾아내기 > 값이 너무 크거나 작은 경우 제외\n",
    "- 날짜별로 확인 후 비어있는 값 채워넣기 (전/다음날 이용)\n",
    "    - 13947개 데이터 중 rain, wind, temperature 갯수 보면 몇개 비어있는지 확인 가능\n",
    "- 합치기.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def set_rwt(row):\n",
    "    country = df_weather_code[df_weather_code[2] == row['CTRY_1']]\n",
    "    if country.empty:\n",
    "        return np.NaN\n",
    "    data = df_weather[(df_weather['year'] == row['year']) \n",
    "                      & (df_weather['month'] == row['month']) \n",
    "                      & (df_weather['day'] == row['day'])\n",
    "                      & (df_weather['지점'] == country[1])]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rain'] = np.NaN\n",
    "df_train['wind'] = np.NaN\n",
    "df_train['temperature'] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**전처리해햘 부분**\n",
    "- \"지점/지점명\"을 기본데이터의 CTYR_1의 나라명과 맞춰줘야함\n",
    "    - df_weather_code을 사용하여 변경 필요\n",
    "    - df_wather# 에 CTTRY_1 컬럼을 추가하여 사용\n",
    "- 하루에 한 지점에서 측정한 데이터가 여러개임\n",
    "    - 하루에 한 데이터가 나오도록 전처리 필요\n",
    "- 강수량의 경우 NaN 값이 너무 많음\n",
    "    - 위 전처리들을 한 후에도 많다면 사용불가\n",
    "    - 위 전처리 후에는 적다면 전날/다음날 데이터 기반으로 채워넣기 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add salinity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_salinity = pd.read_csv(os.path.join(root, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ['CTRY_1', 'CTRY_2', 'P_PURPOSE', 'CATEGORY_1', 'CATEGORY_2', 'P_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['REG_DATE', 'P_TYPE', 'P_IMPORT_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns = drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Function to print the MAE (Mean Absolute Error) score\n",
    "def print_score(m : LinearRegression):\n",
    "    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n",
    "           'mae val: ', mean_absolute_error(m.predict(X_valid), y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train['P_PRICE']\n",
    "df_train.drop(columns = 'P_PRICE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_train, target, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "# Function for splitting training and validation data\n",
    "def split_vals(a, n : int): \n",
    "    return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "val_perc = 0.1 # % to use for validation set\n",
    "n_valid = int(val_perc * 100000) \n",
    "n_trn = len(original)-n_valid\n",
    "\n",
    "# Split data\n",
    "raw_train, raw_valid = split_vals(sample, n_trn)\n",
    "X_train, X_valid = split_vals(original, n_trn)\n",
    "y_train, y_valid = split_vals(target, n_trn)\n",
    "\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_valid=sc.transform(X_valid)\n",
    "\n",
    "# Check dimensions of samples\n",
    "print('Sample train shape: ', X_train.shape, \n",
    "      '\\nSample target shape: ', y_train.shape, \n",
    "      '\\nSample validation shape: ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "model.fit(x_train,y_train)\n",
    "cross = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "\n",
    "print('cross_tree',cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(x_train,y_train)\n",
    "cross_svr = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "print('cross_svr',cross_svr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(n_estimators=500,learning_rate=0.05,max_depth=3)\n",
    "model.fit(x_train,y_train)\n",
    "cross_xgboost = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "\n",
    "print('cross_xgboost : ',cross_xgboost.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "cross_linear = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "print(cross_linear)\n",
    "print('cross_linear : ',cross_linear.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor().fit(x_train,y_train)\n",
    "cross_MLP = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "\n",
    "print('croos_MLP : ',cross_MLP.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
