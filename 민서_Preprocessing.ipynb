{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "# Visuzliation Setting\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib import rc\n",
    "from matplotlib import colors\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = os.path.join(os.getcwd(), 'DATA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data\n",
    "빅콘테스트 제공 데이터 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_excel(os.path.join(root, 'train.xlsx'))\n",
    "df_train = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 날짜변수 추가\n",
    "df_train['year'] = df_train['REG_DATE'].dt.year\n",
    "df_train['month'] = df_train['REG_DATE'].dt.month\n",
    "df_train['day'] = df_train['REG_DATE'].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['VALUE_COUNT'] = 0;\n",
    "value_dict = {}\n",
    "for name, value in zip(df_train['P_NAME'].value_counts().index,df_train['P_NAME'].value_counts()):\n",
    "    value_dict[name] = value\n",
    "\n",
    "def value(col):\n",
    "    return value_dict[col]\n",
    "\n",
    "df_train['VALUE_COUNT'] = df_train['P_NAME'].apply(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot encoding\n",
    "P_IMPORT_TYPE 이라는 특수한 컬럼에 대한 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_type_list = set()\n",
    "for tmp in df_train.P_IMPORT_TYPE.unique():\n",
    "    for a in tmp.split(','):\n",
    "        import_type_list.add(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in import_type_list:\n",
    "    df_train[name] = 0\n",
    "    df_train.loc[df_train['P_IMPORT_TYPE'].str.contains(name, regex=False), name] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather_code = pd.read_excel(os.path.join(root, 'weather_code.xlsx'), header=None, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_list = [pd.read_csv(os.path.join(root, 'weather_raw_20151228-20161227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'weather_raw_20161228-20171227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'weather_raw_20171228-20181227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'weather_raw_20181228-20191227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'weather_raw_20191228-20201227.csv'), encoding='euc-kr') , \n",
    "                pd.read_csv(os.path.join(root, 'weather_raw_20201228-20210818.csv'), encoding='euc-kr')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "- '지점'에 따른 나라명 컬럼 (country) 추가\n",
    "- 각 나라, 일자 별로 평균 강수량, 풍속, 기온 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 지점에 따라 나라명 추가\n",
    "def set_country(row):\n",
    "    data = df_weather_code[df_weather_code[1] == row['지점']]\n",
    "    if data.empty:\n",
    "        return \"\"\n",
    "    return data.iloc[0][2]\n",
    "\n",
    "\n",
    "def preprocess_weather(df_weather):\n",
    "    # 날짜 정보 정리\n",
    "    df_weather['year'] = df_weather['일시'].astype('str').str[:4].astype('int')\n",
    "    df_weather['month'] = df_weather['일시'].astype('str').str[5:7].astype('int')\n",
    "    df_weather['day'] = df_weather['일시'].astype('str').str[8:10].astype('int')\n",
    "    # 1차 평균\n",
    "    df_weather['rain'] = df_weather[['지점', 'year', 'month', 'day', '강수량']].groupby(['지점', 'year', 'month', 'day']).transform('mean')\n",
    "    df_weather['wind'] = df_weather[['지점', 'year', 'month', 'day', '풍속']].groupby(['지점', 'year', 'month', 'day']).transform('mean')\n",
    "    df_weather['temperature'] = df_weather[['지점', 'year', 'month', 'day', '기온']].groupby(['지점', 'year', 'month', 'day']).transform('mean')\n",
    "    # 컬럼/행 정리\n",
    "    df_weather.drop(columns = ['지점명', '일시', '강수량', '풍속', '기온'], inplace=True)\n",
    "    df_weather.drop_duplicates(inplace=True)\n",
    "    # 나라명 추가\n",
    "    df_weather['country'] = \"\"\n",
    "    for i, row in df_weather.iterrows():\n",
    "        df_weather.at[i, 'country'] = set_country(row)\n",
    "    # 2차 평균\n",
    "    df_weather['rain'] = df_weather[['country', 'year', 'month', 'day', 'rain']].groupby(['country', 'year', 'month', 'day']).transform('mean')\n",
    "    df_weather['wind'] = df_weather[['country', 'year', 'month', 'day', 'wind']].groupby(['country', 'year', 'month', 'day']).transform('mean')\n",
    "    df_weather['temperature'] = df_weather[['country', 'year', 'month', 'day', 'temperature']].groupby(['country', 'year', 'month', 'day']).transform('mean')\n",
    "    # 컬럼/행 정리\n",
    "    df_weather.drop(columns = ['지점'], inplace=True)\n",
    "    df_weather.drop_duplicates(inplace=True)\n",
    "    # 인덱스 정리\n",
    "    df_weather.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for df in weather_list:\n",
    "    preprocess_weather(df)\n",
    "df_weather = pd.concat(rwt_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>rain</th>\n",
       "      <th>wind</th>\n",
       "      <th>temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13947.000000</td>\n",
       "      <td>13947.000000</td>\n",
       "      <td>13947.000000</td>\n",
       "      <td>9561.000000</td>\n",
       "      <td>11895.000000</td>\n",
       "      <td>11895.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018.258407</td>\n",
       "      <td>6.276762</td>\n",
       "      <td>15.697426</td>\n",
       "      <td>-20.158210</td>\n",
       "      <td>3.535292</td>\n",
       "      <td>17.914166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.613987</td>\n",
       "      <td>3.414373</td>\n",
       "      <td>8.809565</td>\n",
       "      <td>79.127632</td>\n",
       "      <td>5.846954</td>\n",
       "      <td>9.676148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-156.116667</td>\n",
       "      <td>-10.577841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>-6.661111</td>\n",
       "      <td>2.168701</td>\n",
       "      <td>11.250038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.165833</td>\n",
       "      <td>2.958333</td>\n",
       "      <td>20.135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>3.915909</td>\n",
       "      <td>5.768750</td>\n",
       "      <td>25.950781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>915.000000</td>\n",
       "      <td>15.125000</td>\n",
       "      <td>33.145833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year         month           day         rain          wind  \\\n",
       "count  13947.000000  13947.000000  13947.000000  9561.000000  11895.000000   \n",
       "mean    2018.258407      6.276762     15.697426   -20.158210      3.535292   \n",
       "std        1.613987      3.414373      8.809565    79.127632      5.846954   \n",
       "min     2015.000000      1.000000      1.000000  -999.000000   -156.116667   \n",
       "25%     2017.000000      3.000000      8.000000    -6.661111      2.168701   \n",
       "50%     2018.000000      6.000000     16.000000     1.165833      2.958333   \n",
       "75%     2020.000000      9.000000     23.000000     3.915909      5.768750   \n",
       "max     2021.000000     12.000000     31.000000   915.000000     15.125000   \n",
       "\n",
       "        temperature  \n",
       "count  11895.000000  \n",
       "mean      17.914166  \n",
       "std        9.676148  \n",
       "min      -10.577841  \n",
       "25%       11.250038  \n",
       "50%       20.135000  \n",
       "75%       25.950781  \n",
       "max       33.145833  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weather.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 확인필요\n",
    "- outlier 찾아내기 > 값이 너무 크거나 작은 경우 제외\n",
    "- 날짜별로 확인 후 비어있는 값 채워넣기 (전/다음날 이용)\n",
    "    - 13947개 데이터 중 rain, wind, temperature 갯수 보면 몇개 비어있는지 확인 가능\n",
    "- 합치기..\n",
    "- 강수량의 경우 NaN 값이 너무 많음\n",
    "    - 위 전처리들을 한 후에도 많다면 사용불가\n",
    "    - 위 전처리 후에는 적다면 전날/다음날 데이터 기반으로 채워넣기 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def set_rwt(row):\n",
    "    country = df_weather_code[df_weather_code[2] == row['CTRY_1']]\n",
    "    if country.empty:\n",
    "        return np.NaN\n",
    "    data = df_weather[(df_weather['year'] == row['year']) \n",
    "                      & (df_weather['month'] == row['month']) \n",
    "                      & (df_weather['day'] == row['day'])\n",
    "                      & (df_weather['지점'] == country[1])]\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['rain'] = np.NaN\n",
    "df_train['wind'] = np.NaN\n",
    "df_train['temperature'] = np.NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salinity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_salinity = pd.read_csv(os.path.join(root, 'salinity_raw.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop Columns & Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_salinity.drop(df_salinity.columns[2], inplace=True, axis=1)\n",
    "# df_salinity = df_salinity[(2015 <= df_salinity['obs_year']) & (df_salinity['obs_year'] <= 2021)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2020, 2021 데이터의 부재로 인해 보류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oil = pd.read_csv(os.path.join(root, 'oil_raw.csv'))\n",
    "df_oil_dubai = pd.read_csv(os.path.join(root, 'oil_raw_dubai.csv'))\n",
    "df_oil_brent = pd.read_csv(os.path.join(root, 'oil_raw_brent.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_oil(df):\n",
    "    df['year'] = df['날짜'].str[:4]\n",
    "    df['month'] = df['날짜'].str[6:8]\n",
    "    df['day'] = df['날짜'].str[10:12]\n",
    "    df['date'] = pd.to_datetime(df['year'] + df['month'] + df['day'])\n",
    "    df = df.query('date.dt.dayofweek == 0')\n",
    "    df.drop(columns = ['날짜', '오픈', '고가', '저가', '거래량', '변동 %'], inplace=True, axis=1)\n",
    "    df.sort_index(ascending=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_oil = preprocess_oil(df_oil)\n",
    "df_oil_dubai = preprocess_oil(df_oil_dubai)\n",
    "df_oil_brent = preprocess_oil(df_oil_brent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oil: 288 \n",
      "dubai: 260 \n",
      "brent: 285\n"
     ]
    }
   ],
   "source": [
    "print(\"oil:\", len(df_oil), \"\\ndubai:\", len(df_oil_dubai), \"\\nbrent:\", len(df_oil_brent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oil과 비교하였을 때 dubai의 경우 28개, brent의 경우 3개의 데이터가 적다  \n",
    "따라서 df_oil 데이터를 사용하도록 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add to Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = ['CTRY_1', 'CTRY_2', 'P_PURPOSE', 'CATEGORY_1', 'CATEGORY_2', 'P_NAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.get_dummies(df_train, columns=one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drop columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop = ['REG_DATE', 'P_TYPE', 'P_IMPORT_TYPE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(columns = drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Function to print the MAE (Mean Absolute Error) score\n",
    "def print_score(m : LinearRegression):\n",
    "    res = ['mae train: ', mean_absolute_error(m.predict(X_train), y_train), \n",
    "           'mae val: ', mean_absolute_error(m.predict(X_valid), y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = df_train['P_PRICE']\n",
    "df_train.drop(columns = 'P_PRICE', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_test_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-9655fa28f670>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'train_test_split' is not defined"
     ]
    }
   ],
   "source": [
    "# x_train, x_test, y_train, y_test = train_test_split(df_train, target, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "\n",
    "# Function for splitting training and validation data\n",
    "def split_vals(a, n : int): \n",
    "    return a[:n].copy(), a[n:].copy()\n",
    "\n",
    "val_perc = 0.1 # % to use for validation set\n",
    "n_valid = int(val_perc * 100000) \n",
    "n_trn = len(df_train)-n_valid\n",
    "\n",
    "# Split data\n",
    "raw_train, raw_valid = split_vals(df_train, n_trn)\n",
    "X_train, X_valid = split_vals(df_train, n_trn)\n",
    "y_train, y_valid = split_vals(target, n_trn)\n",
    "\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_valid=sc.transform(X_valid)\n",
    "\n",
    "# Check dimensions of samples\n",
    "print('Sample train shape: ', X_train.shape, \n",
    "      '\\nSample target shape: ', y_train.shape, \n",
    "      '\\nSample validation shape: ', X_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- metric 선정하기\n",
    "- base model 선정 > 전처리 최소화 + linear regression model 로 정확도 구하기\n",
    "- 모델마다 최적화하기\n",
    "- 모델끼리 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor(n_estimators=500,random_state=0)\n",
    "model.fit(x_train,y_train)\n",
    "cross = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "\n",
    "print('cross_tree',cross.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "model = SVR()\n",
    "model.fit(x_train,y_train)\n",
    "cross_svr = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "print('cross_svr',cross_svr.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "model = XGBRegressor(n_estimators=500,learning_rate=0.05,max_depth=3)\n",
    "model.fit(x_train,y_train)\n",
    "cross_xgboost = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "\n",
    "print('cross_xgboost : ',cross_xgboost.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "cross_linear = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "print(cross_linear)\n",
    "print('cross_linear : ',cross_linear.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "model = MLPRegressor().fit(x_train,y_train)\n",
    "cross_MLP = cross_val_score(model,x_test,y_test,cv = 5)\n",
    "\n",
    "print('croos_MLP : ',cross_MLP.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
